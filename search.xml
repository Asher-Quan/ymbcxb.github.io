<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[布隆过滤器]]></title>
    <url>%2F2019%2F06%2F23%2F%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%2F</url>
    <content type="text"><![CDATA[先探讨一个问题？ 现在有50亿个电话号码，现在要快速准确判断这些电话号码是否已经存在？ 数据库查询？太慢了 数据使用集合存放在内存？内存浪费 布隆过滤器！ 布隆过滤器什么是布隆过滤器它实际上是一个很长的二进制向量和一系列随机映射函数 布隆过滤器的实现原理当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。 画个图描述一下 布隆过滤器的误差率直观因素：m/n的比率，hash函数的个数 1个元素，1个hash函数，任意一个比特为1的概率为1/m，依然为0的概率为1-1/m k给函数，依然为0的概率为（1-1/m）^k，n个元素，依然为0的概率为(1-1/m)^nk 被设置为1的概率为1-(1-1/m)^nk 新元素权重的概率为（1-(1-1/m)^nk）^k 本地布隆过滤器使用Guava来实现 123456789101112131415161718192021public class BloomFilterDemo &#123; public static void main(String[] args) &#123; //构建布隆过滤器 BloomFilter&lt;String&gt; bloomFilter = BloomFilter.create(new Funnel&lt;String&gt;() &#123; @Override public void funnel(String s, PrimitiveSink primitiveSink) &#123; primitiveSink.putString(s, Charsets.UTF_8); &#125; &#125;,10000,0.0001); //插入数据 for (int i = 0 ; i &lt; 1000 ; i++)&#123; bloomFilter.put(&quot;i_&quot;+i); &#125; //测试结果 for (int i = 0 ; i &lt; 1005 ; i++)&#123; if(!bloomFilter.mightContain(&quot;i_&quot;+i))&#123; System.out.println(&quot;no&quot;); &#125; &#125; &#125;&#125; 基于Redis的布隆过滤器redis 在 4.0 的版本中加入了 module 功能，布隆过滤器可以通过 module 的形式添加到 redis 中，所以使用 redis 4.0 以上的版本可以通过加载 module 来使用 redis 中的布隆过滤器 在Docker中 12345678&gt; docker run -d -p 6379:6379 --name bloomfilter redislabs/rebloom&gt; docker exec -it bloomfilter redis-cli# redis-cli# 127.0.0.1:6379&gt;# 127.0.0.1:6379&gt; BF.ADD newFilter foo(integer) 1# 127.0.0.1:6379&gt; BF.EXISTS newFilter foo(integer) 1]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis-缓存设计]]></title>
    <url>%2F2019%2F05%2F27%2FRedis-%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[缓存有什么作用？先来看一幅图 缓存主要带来了什么好处呢？ 加速读写 因为缓存通常都是全内存的（例如Redis、Memcache），而存储层通常读写性能不够强悍（例如MySQL），通过缓存的使用可以有效地加速读写，优化用户体验 降低后端负载 帮助后端减少访问量和复杂计算（例如很复杂的SQL语句），在很大程度降低了后端的负载 当然，缓存能够给我们带来好的方便，但是也加大了开发者的开发成本 接下来我们就来学习下如何使用Redis来设计缓存，以及注意的问题： 缓存更新策略缓存中的数据通常都是有生命周期的，需要在指定时间后被删除或更新，这样可以保证缓存空间在一个可控的范围。 三种策略： LRU/LFU/FIFO算法剔除通常用于缓存使用量超过了预设的最大值时候，如何对现有的数据进行剔除。例如Redis使用maxmemory-policy这个配置作为内存最大值后对于数据的剔除策略,还要设置maxmemory（最大内存） maxmemory 默认为0（代表不限制Redis的内存使用） maxmemory-policy有六种策略 noeviction: 不进行置换，表示即使内存达到上限也不进行置换，所有能引起内存增加的命令都会返回error allkeys-lru: 优先删除掉最近最不经常使用的key，用以保存新数据 volatile-lru: 只从设置失效（expire set）的key中选择最近最不经常使用的key进行删除，用以保存新数据 allkeys-random: 随机从all-keys中选择一些key进行删除，用以保存新数据 volatile-random: 只从设置失效（expire set）的key中，选择一些key进行删除，用以保存新数据 volatile-ttl: 只从设置失效（expire set）的key中，选出存活时间（TTL）最短的key进行删除，用以保存新数据 优点使用简单，只用修改对应的配置文件就可以 缺点数据的清理由选择算法决定，开发人员只能选择置换内存的算法策略，所以数据的一致性是最差的 超时剔除超时剔除通过给缓存数据设置过期时间，让其在过期时间后自动删除，Redis提供了expire命令 1$ EXPIRE key time(s) 优点使用简单，只需要设置对应key的过期时间即可 能够允许在一段时间内的数据不一致或者是数据对实际业务影响不大的场景，此方案还是很好的解决方案 缺点数据不一致：如果，数据对实际业务影响比较大的场景，谨慎使用，特别涉及到金钱交易的情况下 主动更新应用方对于数据的一致性要求高，需要在真实数据更新后，立即更新缓存数据。例如可以利用消息系统或者其他方式通知缓存更新 优点可以根据自己的业务需求来完成缓存的更新，解决了单纯使用expire设置过期时间的局限性 一致性最高，但如果主动更新发生了问题，那么这条数据很可能很长时间不会更新，所以建议结合超时剔除一起使用效果会更好 缺点维护成本会比较高，开发者需要自己来完成更新，并保证更新操作的正确性 有两个建议： 低一致性业务建议配置最大内存和淘汰策略的方式使用 高一致性业务可以结合使用超时剔除和主动更新，这样即使主动更新出了问题，也能保证数据过期时间后删除脏数据 缓存粒度很多时候我们缓存的值是后端Mysql或者别的数据库查询出来的值，因为一般来说，复杂的查询比较费时，所以查询出来放进redis是一个比较明智的做法 那么我们要缓存多少，缓存到一个什么层度呢？ 比如说：缓存所有列 1set user:&#123;id&#125; &apos;select * from user where id=&#123;id&#125;&apos; 缓存部分列 12set user:&#123;id&#125; &apos;select &#123;importantColumn1&#125;, &#123;important Column2&#125; ... &#123;importantColumnN&#125;from user where id=&#123;id&#125;&apos; 这个问题就是缓存粒度问题 缓存全部数据要比部分数据占用更多的空间，可能存在以下问题： 全部数据会造成内存的浪费 全部数据可能每次传输产生的网络流量会比较大，耗时相对较大，在极端情况下会阻塞网络 全部数据的序列化和反序列化的CPU开销更大 缓存粒度问题是一个容易被忽视的问题，如果使用不当，可能会造成很多无用空间的浪费，网络带宽的浪费，代码通用性较差等情况，需要综合数据通用性、空间占用比、代码维护性三点进行取舍 缓存穿透 缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，当被别人恶意访问查询一个不存在的数据的时候，请求就会访问到存储层（Mysql），当请求量很大的情况下，Mysql是承受不了的，可能造成后端存储宕掉，而且缓存层也失去了保护存储层的意义 解决办法： 缓存空对象 当第2步存储层不命中后，仍然将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取，这样就保护了后端数据源，缺点： 缓存层中存了更多的键，需要更多的内存空间(也是一种危害) 措施：是将这类的Key设置一个较短的过期时间 缺点：缓存层和存储层的短暂不一致 措施：可以利用消息系统或者其他方式清除掉缓存层中的空对象 布隆过滤器 在访问缓存层之前，将存在的key用布隆过滤器提前保存起来,当访问不存在的key的时候，布隆过滤器直接返回，可以避免访问缓存层和存储层 使用互斥锁：根据key获取value值为空时，锁上，从数据库中load数据后再释放锁（适合并发量比较低的情况，因为并发量很大的情况下，会导致阻塞和死锁的情况） 缓存雪崩由于缓存层承载大量请求，当cache服务异常/脱机，流量打向了后端的存储层，造成存储层也会级联宕机的情况，除了缓存服务异常和脱机的情况，还有另外一种情况：缓存key大片面积失效（时间到期）也会导致缓存雪崩 关于解决缓存服务异常和脱机需要注意的几个问题: 保证缓存层服务高可用性 如果缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务 依赖隔离组件为后端限流并降级 我们需要对重要的资源（例如Redis、MySQL、HBase、外部接口）都进行隔离，让每种资源都单独运行在自己的线程池中，即使个别资源出现了问题，对其他服务没有影响 提前演练 演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定 解决方案： 在设置缓存时候，不设置统一的过期时间，而是在一个范围内随机设置过期时间，以防止大量的key同时过期 使用互斥锁：根据key获取value值为空时，锁上，从数据库中load数据后再释放锁（适合并发量比较低的情况，因为并发量很大的情况下，会导致阻塞和死锁的情况） 提前使用互斥锁，比如key10S过期，在内部使用一个标识key 8S过期，假设标识key过期的时候，就给对应的Key延长过期时间 双缓存，缓存A和缓存B，A设置超时时间，B不设值超时时间，先从A读缓存，如果A没有则读B，并且更新A缓存和B缓存（对存储的消耗比较大）]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-抽象工厂]]></title>
    <url>%2F2019%2F05%2F27%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%2F</url>
    <content type="text"><![CDATA[抽象工厂抽象工厂模式提供一个创建一系列相关或相互依赖对象的接口 客户端（应用层）不依赖于产品类实例如何被创建，实现等细节 强调一系列相关的产品对象（属于同一产品族）一起使用创建对象需要大量重复的代码 具体产品在应用层代码隔离，无需关系创建细节 将一个系列的产品族一起创建 产品族：这里画个图来帮助理解 比如说，小米的所有子产品都属于一个产品族 前面学的工厂方法所关注的就是产品等级结构：就如图中的小米电脑和苹果电脑，都属于电脑 这里的抽象工厂关注的是一个产品族:我们只需要指出一个产品所处于的产品族以及所属的等级结构就能唯一确定这个产品（举个例子：从小米工厂取出的手机——》就是小米手机） Demo工厂接口 1234567/** * 品牌工厂 */public interface BrandFactory &#123; Phone getPhone();//获得手机 LapTop getLapTop();//获得手提电脑&#125; 两个抽象实体： 123456/** * 手提电脑 */public abstract class LapTop &#123; public abstract void produce();//生产手提电脑&#125; 123456/** * 手机 */public abstract class Phone &#123; public abstract void produce();//生产手机&#125; 两个具体的工厂: 1234567891011121314/** * 苹果工厂 */public class AppleFactory implements BrandFactory &#123; @Override public Phone getPhone() &#123; return new ApplePhone(); &#125; @Override public LapTop getLapTop() &#123; return null; &#125;&#125; 1234567891011121314/** * 小米工厂 */public class MiFactory implements BrandFactory &#123; @Override public Phone getPhone() &#123; return new MiPhone(); &#125; @Override public LapTop getLapTop() &#123; return new MiLapTop(); &#125;&#125; 两个手机的实现类： 123456789/** * 小米手机 */public class MiPhone extends Phone &#123; @Override public void produce() &#123; System.out.println(&quot;生产小米手机&quot;); &#125;&#125; 123456789/** * 苹果手机 */public class ApplePhone extends Phone &#123; @Override public void produce() &#123; System.out.println(&quot;生产苹果手机&quot;); &#125;&#125; 两个笔记本的实现类 123456789/** * 苹果笔记本 */public class AppleLapTop extends LapTop &#123; @Override public void produce() &#123; System.out.println(&quot;生产苹果笔记本&quot;); &#125;&#125; 123456789/** * 小米笔记本 */public class MiLapTop extends LapTop &#123; @Override public void produce() &#123; System.out.println(&quot;生产小米笔记本&quot;); &#125;&#125; 看一下类图 写个测试类 123456789public class TestDemo &#123; public static void main(String[] args) &#123; BrandFactory brandFactory = new MiFactory(); Phone phone = brandFactory.getPhone(); LapTop lapTop = brandFactory.getLapTop(); phone.produce();//输出生产小米手机 lapTop.produce();//输出小米笔记本 &#125;&#125; 结论在抽象工厂里面，对于应用层，根本不关心手机和笔记本的实现过程，只关心对应的一个工厂，在哪个工厂取得的产品也就是什么工厂的产品，还是上面的例子（小米工厂拿到的手机就是小米手机） 应用层代码和具体的手机是解耦的，和具体的笔记本电脑也是解耦的 工厂方法和抽象工厂的最大区别是： 工厂方法关注的是同一产品等级，抽象工厂关注的是产品族 抽象工厂 优点： 应用层代码不和具体的产品发生依赖，只和具体的产品族工厂发生依赖 从某个工厂取出的产品，一定是属于这个工厂的产品 扩展性好，比如增加一个华为的品牌，只用增加一个工厂，一个手机，一个笔记本即可，其余不用发生改变（符合开闭原则）产品等级稳定的情况下 缺点： 新增产品等级的时候，会在原有的结构上进行较大的改动（比如说，增加一个小米生产的别的产品）此时就违背了开闭原则，所以要注意场景使用 举个真实的例子：在java.sql这个包下Connection这个接口里面PrepareStatement和Statement都是属于一个产品族在这里，就使用到了抽象工厂的设计模式]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-Cluster常见问题]]></title>
    <url>%2F2019%2F05%2F26%2FRedis-Cluster%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[集群完整性12# 默认为yescluster-require-full-coverage yes 默认的配置保证了两个问题： 集群中的161384个槽全部可用，保证了集群的完整性 节点故障或者故障转移的时候，进行set操作会报 (error) CLUSTERRDOWN The cluster is down 一个节点坏了，整个集群都不可用了，这在实际业务上是有问题的 所以我们通常需要将它修改为no 带宽消耗RedisCluster会定期进行Ping/Pong进行心跳检测，也会进行信息的一个交互 官方建议RedisCluster的节点数量不要超过1000个，因为RedisCluster对带宽的消耗很高 主要来自下面三个方面 消息发送频率，节点发现与其他节点最后通信时间超过cluster-node-timeout/2时会直接发送ping消息 消息数据量：slots槽数组（2KB空间）和整个集群1/10的状态数据（10个节点的状态数据约1KB） 节点部署的机器规模：集群分布的机器越多且每台机器划分的节点数越均匀，则集群内整体的可用带宽就越高 举个例子： 规模：节点200个，20台物理机（每台10个节点） 1cluster-node-timeout = 15000 ping/pong的带宽为25Mb 1cluster-node-timeout = 20000 ping/pong带宽会低于15Mb 优化： 避免多业务使用一个集群，大业务可以多集群 cluster-node-timeout:带宽和故障转移速度的均衡 尽量均匀分配到多机器上，保证高可用和带宽 Pub/Sub广播问题：publish在集群每个节点广播：加重带宽 解决：针对这种情况建议使用sentinel结构专门用于Pub/Sub功能，从而规避这一问题。 数据倾斜集群内特定节点数据量过大将导致节点之间负载不均，影响集群均衡和运维成本。 数据倾斜主要分为以下几种： ·节点和槽分配严重不均。 当节点对应槽数量不均匀时，可以使用redis-trib.rb rebalance命令进行平衡 ·不同槽对应键数量差异过大。 通过命令：cluster countkeysinslot{slot}可以获取槽对应的键数量，识别出哪些槽映射了过多的键。再通过命令clustergetkeysinslot{slot}{count}循环迭代出槽下所有的键。 ·集合对象包含大量元素。 对于大集合对象的识别可以使用redis-cli–bigkeys命令识别 ·内存相关配置不一致。 当集群大量使用hash、set等数据结构时，如果内存压缩数据结构配置不一致，极端情况下会相差数倍的内存，从而造成节点内存量倾斜。 请求倾斜集群内特定节点请求量/流量过大将导致节点之间负载不均，影响集群均衡和运维成本。 避免方式如下： 合理设计键，热点大集合对象做拆分或使用hmget替代hgetall避免整体读取。 不要使用热键作为hash_tag，避免映射到同一槽。 对于一致性要求不高的场景，客户端可使用本地缓存减少热键调用。 读写分离只读连接集群模式下从节点不接受任何读写请求，发送过来的键命令会重定向到负责槽的主节点上（其中包括它的主节点） 当需要使用从节点分担主节点读压力时，可以使用readonly命令打开客户端连接只读状态。 注意：readonly是连接级别生效，每次连接都要开启一遍才可以 读写分离问题：复制延迟，读取过期数据，从节点故障 集群模式下读写分离涉及对客户端修改如下： 维护每个主节点可用从节点列表 针对读命令维护请求节点路由 从节点新建连接开启readonly转态 集群模式下读写分离成本比较高，可以直接扩展主节点数量提高集群性能，一般不建议集群模式下做读写分离 集群读写分离有时用于特殊业务场景如： 利用复制的最终一致性使用多个从节点做跨机房部署降低读命令网络延迟。 主节点故障转移时间过长，业务端把读请求路由给从节点保证读操作可用。 数据迁移应用Redis集群时，常需要把单机Redis数据迁移到集群环境。redis-trib.rb工具提供了导入功能，用于数据从单机向集群环境迁移的场景，命令如下： 1$ redis-trib.rb import host:port --from &lt;arg&gt; --copy --replace redis-trib.rb import命令内部采用批量scan和migrate的方式迁移数据。这种迁移方式存在以下缺点： 迁移只能从单机节点向集群环境导入数据。 不支持在线迁移数据，迁移数据时应用方必须停写，无法平滑迁移数据。 迁移过程中途如果出现超时等错误，不支持断点续传只能重新全量导入。 使用单线程进行数据迁移，大数据量迁移速度过慢 正因为这些问题，社区开源了很多迁移工具，这里推荐一款唯品会开发的redis-migrate-tool，该工具可满足大多数Redis迁移需求，特点如下： ·支持单机、Twemproxy、Redis Cluster、RDB/AOF等多种类型的数据迁移 工具模拟成从节点基于复制流迁移数据，从而支持在线迁移数据，业务方不需要停写 采用多线程加速数据迁移过程且提供数据校验和查看迁移状态等功能 集群VS单机集群限制 key批量操作支持有限：mget，mset必须在一个slot上 key事务和Lua支持有限：操作的key必须在一个节点上 key是数据分区的最小粒度，不支持bigkey 不支持多个数据库：集群下只有一个db0 复制只支持复制一层，不支持树形复制结构 思考分布式Redis RedisCluster:用来满足容量和性能的扩展性，但是要看业务来使用 大多数情况客户端性能会降低 命令无法跨节点使用 Lua和事务无法跨节点使用 客户端维护更加复杂]]></content>
  </entry>
  <entry>
    <title><![CDATA[Redis-Cluster(集群)]]></title>
    <url>%2F2019%2F05%2F20%2FRedis-Cluster(%E9%9B%86%E7%BE%A4)%2F</url>
    <content type="text"><![CDATA[Redis集群为什么要引入Redis集群 单机会造成什么问题，官方说法：单机Redis支持十万的并发量，如果我需要二十万呢？三十万呢？这时候就要用到Redis集群，撇开Redis集群不说，集群，就是用来分担单机的压力，无论是访问的压力，查询的压力还是流量的压力，为什么通常都要使用集群来解决呢？比如电脑内存不够往往会想着买一条内存条，但是还不够呢？一台电脑不断加装，成本越来越贵，很不划算，当成本大于我重新买一台电脑的时候，我当然选择两台电脑就是这个意思，更何况通常集群都是上百台呢 RedisCluster的安装原生安装配置节点启动6个redis，配置的端口从7000-7005，以下是配置文件 12345678port 7000daemonize yesdir &quot;/redis/data&quot;logfile &quot;7000.log&quot;dbfilename &quot;dump-7000.rdb&quot;cluster-enabled yescluster-config-file nodes-7000.confcluster-require-full-coverage no 配置meet12345$ redis-cli -p 7000 cluster meet 127.0.0.1 7001$ redis-cli -p 7000 cluster meet 127.0.0.1 7002$ redis-cli -p 7000 cluster meet 127.0.0.1 7003$ redis-cli -p 7000 cluster meet 127.0.0.1 7004$ redis-cli -p 7000 cluster meet 127.0.0.1 7005 分配槽编写一个脚本addslots.sh 1234567start=$1end=$2port=$3for slot in `seq $&#123;start&#125; $&#123;end&#125;`do redis-cli -p $&#123;port&#125; cluster addslots $&#123;slot&#125;done 分配槽给节点，这里我有六个redis，但是我只分配将槽分成三份，另外三份来用做slave 123$ sh addslots.sh 0 5461 7000$ sh addslots.sh 5462 10922 7001$ sh addslots.sh 10923 16383 7002 主从分配上面将槽分配给了7000，7001，7002，将其对应的slave是7003，7004，7005 1234#replicate后面接对应节点的id号，id号可以看我上面那张图，一一对应的，在redis-cli下通过cluster nodes可以查询$ redis-cli -p 7003 cluster replicate 84b0e3f7ba4d7a709d8b25fe4844b66296af71d8$ redis-cli -p 7004 cluster replicate 6b17f1a9bb7ee845c1d8c012c2805df76fb9b943$ redis-cli -p 7005 cluster replicate e32dd59b6b1205ca88050e2124c40ba37200a674 安装结束： 123$ redis-cli -p 7000$ set k1 v1OK 可以进入redis-cli后能够进行set操作了 官方工具安装首先按照步骤按照一下官方工具 1234567wget https://cache.ruby-lang.org/pub/ruby/2.6/ruby-2.6.3.tar.gzcd ruby-2.6.3./configure -prefix=/usr/local/rubymake &amp;&amp; make installwget http://rubygems.org/downloads/redis-3.3.0.gemgem install -l redis-3.3.0.gemgem list -- check redis gem 然后和上面一样，跑六个节点，全部启动起来 8000-8005端口 12345678port 8005daemonize yesdir &quot;/redis/data&quot;logfile &quot;8005.log&quot;dbfilename &quot;dump-8005.rdb&quot;cluster-enabled yescluster-config-file nodes-8005.confcluster-require-full-coverage no 进入redis下的src目录 123$ cd /redis/src#使用工具来创建集群,其中数量1代表一个主节点配置1个从节点$ ./redis-trib.rb create --replicas 1 127.0.0.1:8000 127.0.0.1:8001 127.0.0.1:8002 127.0.0.1:8003 127.0.0.1:8004 127.0.0.1:8005 对上面没问题可以输入yes 可以通过以下命令，查看集群是否搭建成功 12$ redis-cli -p 8000 cluster nodes$ redis-cli -p 8000 cluster info 集群扩容 启动两个独立的redis，其中8006和8007是独立的 将集群种的节点对独立的节点进行meet操作 12$ redis-cli -p 8000 cluster meet 127.0.0.1 8006$ redis-cli -p 8000 cluster meet 127.0.0.1 8007 主从的分配 1$ redis-cli -p 8006 cluster replicate 8007的runId 分配槽，使用redis-trib的工具 进入 src目录下， 1$ ./redis-trib.rb reshard 127.0.0.1:8000 分配完成 集群缩容./redis-trib.rb reshard – from 不要的节点的runId –to 分配的节点的runId –slots 多少个槽 1366 让哪个端口去执行示例： 1$ ./redis-trib.rb reshard --from 9334fcdbc2453637e86f1b6664a8c86413eb87d4 --to d576410d1da0cd11f29035550ef0eaf81a811ea7 --slots 1366 127.0.0.1:8007 按照这个方法可以把槽分配给其他节点 把所有槽都分配完成后，可以去删除节点 ./redis-trib.rb del-node 分配一个Ip地址:端口 运行的runId 示例 1$ ./redis-trib.rb del-node 127.0.0.1:8000 9334fcdbc2453637e86f1b6664a8c86413eb87d4 客户端首先简单讲一下ASK重定向和Moved重定向 1234进入redis-cli$ redis-cli -p 8000$ set k1 v1(error) MOVED 12706 192.168.25.155:8002 这个就是MOVED异常 什么意思呢？就是说，当你要设置一个key的时候，如果当前这个key的hash值计算出来的槽不在当前节点，就会报错，错误会告诉你应该去哪个节点里面进行一个set操作 12345进入集群下的redis-cli$ redis-cli -c -p 8000$ set k1 v1-&gt; Redirected to slot [12706] located at 192.168.25.155:8002OK 这就是Moved重定向，会自动帮我们进行一个重定向到8002端口的Redis然后进行一个set操作 接下来讲讲ASK重定向 什么是ASK重定向呢？ ask异常是在槽的迁移过程才会发生的 什么意思呢，比如访问k1这个槽的节点的时候，节点报ASK异常，说明这个k1当前在我这个节点，但k1这个槽即将迁移到新的节点当中，ask的重定向会返回一个迁移到的目标节点的信息 Smart客户端,会识别ask异常和moved异常来进行一个对节点的切换 JavaDemo： 123456789101112131415161718192021222324252627282930313233343536373839public class JedisClusterDemo &#123; private Logger logger = LoggerFactory.getLogger(JedisClusterDemo.class); private Set&lt;HostAndPort&gt; nodeSet = new HashSet&lt;&gt;(); private JedisCluster jedisCluster = null; private List&lt;String&gt; hostPortList = new ArrayList&lt;&gt;(); @Before public void setup()&#123; hostPortList.add(&quot;192.168.25.155:8000&quot;); hostPortList.add(&quot;192.168.25.155:8001&quot;); hostPortList.add(&quot;192.168.25.155:8002&quot;); hostPortList.add(&quot;192.168.25.155:8003&quot;); hostPortList.add(&quot;192.168.25.155:8004&quot;); hostPortList.add(&quot;192.168.25.155:8005&quot;); JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); for(String hostPort : hostPortList)&#123; String[] arr = hostPort.split(&quot;:&quot;); if(arr.length != 2)&#123; continue; &#125; nodeSet.add(new HostAndPort(arr[0],Integer.parseInt(arr[1]))); &#125; try &#123; jedisCluster = new JedisCluster(nodeSet,1000,7,jedisPoolConfig); &#125; catch (Exception e) &#123; logger.error(e.getMessage(),e); &#125; &#125; @Test public void testDemo()&#123; jedisCluster.set(&quot;k1&quot;,&quot;v1&quot;); System.out.println(jedisCluster.get(&quot;k1&quot;)); &#125; @After public void destroy()&#123; if (jedisCluster != null)&#123; jedisCluster.close(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-Sentinel(哨兵)]]></title>
    <url>%2F2019%2F05%2F19%2FRedis-Sentinel(%E5%93%A8%E5%85%B5)%2F</url>
    <content type="text"><![CDATA[主从复制的问题手动故障的转移 假设master出现故障了，两个slave都出现了问题 这时候应该怎么解决呢？ 将上面的slave做一个slaveof no one的操作，将其变为独立的master 将客户端指向新的master 将下面的slave指向新的master 这个过程实际操作起来还是比较麻烦的，虽然说我们是可以使用脚本来进行执行，但是，编写脚本的所需要的能力还是比较大，怎么判断redis节点出现问题，怎么通知客户端去重新指向等等的问题 写能力和存储能力受限在主从复制的架构上，master节点负责写，slave节点负责读，即便有多个从节点，但这些从节点存储的数据也只是主节点的数据副本，实际上也就相当于数据只存储在主节点一台机器中 Redis Sentinel 架构 首先，你可以把一个sentinel想象是一个redis的进程，不同的是sentinel不负责存储数据，它是负责对redis的一个故障判断、故障转移以及通知客户端的功能。另外，由上图可以看出sentinel不是一个而是多个，这样一来可以保证我们判断故障的一个公平性（后面可以设置几个sentinel认为节点有故障才算数），同时也保证了我们的高可用（即当一个sentinel节点挂了，仍然可以保证我们这个sentinel机制是完美的）。 ​ 那对客户端来说就再也不会直接从redis中获取信息，也就是说在我们客户端中不会记录redis的地址（某个IP），而是记录sentinel的地址，这样我们可以直接从sentinel获取的redis地址，因为sentinel会对所有的master、slave进行监控，它是知道到底谁才是真正的master的，例如我们故障转移，这时候对于sentinel来说，master是变了的，然后通知客户端。而客户端根本不用关心到底谁才是真正的master，只关心sentinel告知的master。 Redis Sentinel故障转移的步骤 多个sentinel发现并确认master有问题。 选举出一个sentinel作为领导。（因为故障转移一系列操作只需要一个sentinel就可以完成） 从多个slave中选出一个slave作为新的master 通知其余slave成为新的master的slave 通知客户端主从变化（这样客户端就不会有读取失败的问题） 等待老的master复活成为新的master的slave（sentinel依然会对老的master进行监控是否复活） 这里简单提一下：我们的一套sentinel是可以监听多套master+slave的组合，这样可以有效节省资源，其中每套master+slave会使用一个master-name作为一个标识。 Redis Sentinel演示首先配置两个Redis，一主二从 主：port：8000 12345port 8000daemonize yespidfile /var/run/redis-8000.pidlogfile &quot;8000.log&quot;dir &quot;/redis/data&quot; 从节点：port:8001和8002 12345678910111213port 8001daemonize yespidfile /var/run/redis-8001.pidlogfile &quot;8001.log&quot;dir &quot;/redis/data&quot;slaveof 127.0.0.1 8000-----------------------------------port 8002daemonize yespidfile /var/run/redis-8002.pidlogfile &quot;8002.log&quot;dir &quot;/redis/data&quot;slaveof 127.0.0.1 8000 启动redis 123$ redis-server redis-8000.conf$ redis-server redis-8001.conf$ redis-server redis-8002.conf 配置sentinel 先从redis文件夹下拷贝sentinel.conf配置文件 1$ cat sentinel.conf | grep -v &quot;#&quot; | grep -v &quot;^$&quot; &gt; redis-sentinel-26379.conf 进行修改配置文件redis-sentinel-26379.conf 12345678910111213141516#端口号port 26379#以守护进程的方式启动daemonize yes#哨兵sentinel的工作目录dir /redis/data#日志文件名logfile &quot;26379.log&quot;# 监控名字为mymaster 的master 主机号为127.0.0.1 端口号为8000 当有两个sentinel认为这个master有问题就会执行相应的措施sentinel monitor mymaster 127.0.0.1 8000 2# 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒sentinel down-after-milliseconds mymaster 30000# 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行同步sentinel parallel-syncs mymaster 1# 故障转移的超时时间 failover-timeoutsentinel failover-timeout mymaster 180000 启动sentinel 1$ redis-sentinel redis-sentinel-26379.conf 再去查看一下配置文件 发生配置文件发生了改变，删除掉一些默认配置，而且加上了一些配置信息，比如从节点的信息（因为我们一开始指定主节点的时候，sentinel会获取主节点的信息，从而知道了slave的信息） 在创建两个sentinel 12345$ sed &quot;s/26379/26380/g&quot; redis-sentinel-26379.conf &gt; redis-sentinel-26380.conf$ sed &quot;s/26379/26381/g&quot; redis-sentinel-26379.conf &gt; redis-sentinel-26381.conf#开启redis-sentinel$ redis-sentinel redis-sentinel-26380.conf$ redis-sentinel redis-sentinel-26381.conf 可以查看redis-sentinel 26381的信息或者26382的信息都是可以发现sentinel的数量已经变成了3个 1$ redis-cli -p 26381 info sentinel 使用客户端观察Java代码： 这里要注意一点，如果是本机则没事，如果是用虚拟机的朋友要把上面的127.0.0.1写成具体的虚拟机地址，比如我这里就是192.168.25.155，如果用的是Docker的朋友们，可以先commit然后再在启动的时候请使用–network=host（使用宿主机的IP地址） 1234567891011121314151617181920212223242526272829303132public class JedisSentinelPoolDemo &#123; private static Logger logger = LoggerFactory.getLogger(JedisSentinelPoolDemo.class); private String masterName = &quot;mymaster&quot;; private Set&lt;String&gt; sentine = new HashSet&lt;String&gt;(); private JedisSentinelPool jedisSentinelPool; @Before public void setup()&#123; sentine.add(&quot;192.168.25.155:26379&quot;); sentine.add(&quot;192.168.25.155:26380&quot;); sentine.add(&quot;192.168.25.155:26381&quot;); jedisSentinelPool = new JedisSentinelPool(masterName,sentine); &#125; @Test public void test01()&#123; int counter = 0; while(true)&#123; counter++; try(Jedis jedis = jedisSentinelPool.getResource())&#123; int index = new Random().nextInt(100000); String key = &quot;k-&quot;+index; String value = &quot;v-&quot;+index; jedis.set(key,value); if(counter % 100 == 0)&#123; logger.info(&quot;&#123;&#125; value is &#123;&#125;&quot;,key,jedis.get(key)); &#125; TimeUnit.MILLISECONDS.sleep(10); &#125;catch (Exception e)&#123; logger.error(e.getMessage(),e); &#125; &#125; &#125;&#125; 这个时候，我们的master是8000，如果停止掉master（模仿宕机） 1$ redid-cli -p 8000 shutdown Java客户端会报错，稍等一会，会发现，日志继续输出？？？ 这就是我们的Redis的Sentinel的机制 Sentinel会去检测Redis中的master是否故障，从而自动的将故障进行一个转移 这都是我们Sentinel去做的，省下了人工去操控的一个麻烦的过程 Sentinel的三个定时任务 每十秒对每个sentinel对master和slave执行info，可以发现slave节点和确认主从节点的关系 每两秒每个sentinel通过master节点的channel交换信息 每一秒每个sentinel对其他sentinel和redis执行ping（心跳检测） 主观下线和客观下线配置文件 12# 节点多久没响应，就对这个节点做主观下线sentinel down-after-milliseconds mymaster 30000 主观下线和客观下线的区别在于，主观下线仅仅是依赖于单独的一个sentinel，而客观下线相当于，超过多少个quorum 都认为这个节点是下线了，那么，这个节点从客观的角度，就是下线了，此时就叫做客观下线 领导者选举只需要一个sentinel节点就可以完成故障的转移 每个主观下线的Sentinel节点向其他Sentinel节点发送命令，要求将它设置为领导者 收到命令的Sentinel节点如果没有同意通过其他Sentinel节点发送的命令，那么将会同意该请求，否则拒绝 如果该Sentinel节点发现自己的票数已经超过Sentinel集合的半数而且超过quorum，那么将成为领导者 如果该过程有多个Sentinel节点成为了领导者，将进行一次重新选举 总结Redis Sentinel是Redis的高可用实现方案： 故障发现 故障自动转移 配置中心 客户端通知 Redis Sentinel从Redis2.8版本开始才正式生产使用，之前版本生产不可用 Redis Sentinel的Sentinel节点个数应该为奇数 Redis Sentinel节点不负责读写，负责监控，和管理节点]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-主从复制]]></title>
    <url>%2F2019%2F05%2F18%2FRedis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[单机版的Redis单机版的Redis能够支持十万的QPS（QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准） 假设需要一百万怎么办？那就多台Redis实现集群 单机版的Redis，万一坏了，怎么办，数据没了怎么办？那就多台Redis进行数据的一个复制 所以有了Redis的主从复制的概念 Redis主从复制主从复制可以理解为，一主多从或者一主一丛（一个主节点可以有多个从节点，一个从节点只能有一个主节点，数据流向是单向的，只能从master到slave） 可以做数据副本，也可以提高扩展读的性能 还可以做读写分离 Redis主从复制的配置实现主从复制有以下两种方式 slaveof命令 配置文件 上demo，首先是用slaveof 先走一遍主节点的配置文件redis-6379.conf 12345daemonize yeslogfile &quot;6379.log&quot;dbfilename dump-6379.rdbdir /redis/data#关闭RDB的save配置 再走一遍从节点的配置文件redis-6380.conf 123456daemonize yeslogfile &quot;6380.log&quot;dbfilename dump-6380.rdbdir /redis/dataslaveof 127.0.0.1 6379#关闭RDB的save配置 启动两个redis 先查看6379端口的redis 1$ info replication 然后查看6380端口的redis 根据上面的两个图，可以看到6379的redis是显示master也就是主节点 而6380的redis是现实slave也就是从节点 接下来是实例操作 1234# 在6379端口的redis进行set$ set k1 v1# 在6380端口的redis进行get$ get k1 会发现6380的redis是可以get到的 如果想将6380的redis变为单独的节点，也就是从节点的 可以动态修改 123$ slaveof no one#再查看信息的分片，会发现，变成master节点了$ info replication 原理主从复制的时候，我们并没有开启RDB和AOP，但是为什么从节点能够把主节点的数据来进行一个记录呢？ 这是因为主从复制的时候会自动触发RDB的产生，实质是主节点fork出一个子进程来进行数据的一个传输（相当于bgsave） 全量复制 内部使用psync ? -1 这个命令第一个参数是runId，第二个参数是偏移量，而由于是第一次复制，slave不知道master的runId，也不知道自己偏移量，这时候会传一个问号和-1，告诉master节点是第一次同步 当master接受到psync ？ -1 时，就知道slave是要全量复制，就会将自己的runID和offset告知slave slave会将master信息保存 master这时会做一个RDB的生成（bgsave） 将RDB发送给slave 将复制缓冲区记录的操作也发送给slave slave清空自己的所有老数据 slave这时就会加载RDB文件以及复制缓冲区数据，完成同步。 全量复制的开销 bgsave的开销，每次bgsave需要fork子进程，对内存和CPU的开销很大 RDB文件网络传输的时间（网络带宽） 从节点清空数据的时间 从节点加载RDB的时间 可能的AOF重写时间（如果我们的从节点开启了AOF，则加载完RDB后会对AOF进行一个重写，保证AOF是最新的） 主从复制的问题读写分离读写分离在数据库层面还是用得挺多的，大多数业务都是读多写少的场景，所以，进行读写分离，能够将读的流量分摊到别的节点中 当然也会存在一些问题： 复制数据延迟（数据复制的延迟，当主节点发生阻塞的时候，会导致读写不一致） 读到过期的数据（主节点删除过期key的时候还没同步到从节点的时候，从节点会有很多脏数据） 从节点故障（从节点宕机之后，如何将访问这个节点的请求进行一个转移） 主从配置不一致 mamemory不一致会导致丢失数据 数据结构优化参数的不一致，导致主从内存不一致 规避全量复制 第一次全量复制 不可避免（但是可以减少危害，小主节点的情况下和在低峰值的情况下做第一次全量复制） 节点运行ID不匹配（主节点重启，运行ID发生了变化） 不可避免 可以使用故障转移的方式，当主节点发生故障的时候，从节点去接替当作主节点 复制积压缓冲区不足（网络中断，部分复制无法满足） 增大复制缓冲区配置rel_backlog_size 规避复制风暴 单主节点复制风暴（主节点重启，或者更换主节点的情况下，会进行大批量的全量复制） 更换节点的拓扑图（没有一个完美的拓扑图，应该结合自己的实际场合来考虑） 单机器的复制风暴（主节点所在的机器挂掉，换一个新的机器，也会进行大批量的全量复制） 主节点分散多台机器上面]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-持久化]]></title>
    <url>%2F2019%2F05%2F17%2FRedis-%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[什么是持久化redis所有数据都是保存在内存当中的，对数据的更新将保存到磁盘上，称之为数据的持久化 如果没有持久化，那断电，宕机，都会导致一个数据的缺失 持久化的两种方式RDBRedis的数据是存储在内存当中的，RDB是通过快照的方式，将内存中的数据存储到硬盘当中的一个文件，这个文件就是RDB文件 RDB的三种触发机制 save(同步)：占用的内存比较小，对性能开销没那么大，但是一旦数据比较多的时候，就会导致阻塞 bgsave(异步)：fork出子进程，子进程来进行一个save操作，不会导致阻塞，但是相对内存的消耗会比较大 自动 全量复制 debug reload 在演示之前，我们需要对我们redis.conf配置文件来进行一个配置 123456789101112131415161718# 以守护进程的方式启动daemonize yes# 当运行多个redis服务时，需要指定不同的pid文件和端口pidfile /var/run/redis:6379.pid# 以端口号为6379启动port 6379# 配置日志文件的存放位置logfile = &quot;6379.log&quot;# 存储至本地数据库时（持久化到rdb文件）是否压缩数据，默认为yesrdbcompression yes#当bgsave执行失败的时候，是否停止redis的工作stop-writes-on-bgsave-error yes#是否校验格式rdbchecksum yes#rdb文件名dbfilename dump6379.rdb# 工作目录（按照自己的电脑进行一个配置）dir /redis/data save（同步机制）1234#执行set方法$ set k1 v1#手动save保存$ save 查看data目录下，会发现有一个文件dump6379.rdb 删除文件再进行下一个实验 bgsave（异步机制）1234#执行set方法$ set k1 v1#手动bgsave保存$ save 同样的，再data目录下，会发现有一个文件dump6379.rdb 删除文件再进行下一个实验 自动（根据配置文件的配置）我们查看一下redis.conf配置文件 12345678# 比如默认配置文件中的设置，就设置了三个条件## save 900 1 900秒内至少有1个key被改变# save 300 10 300秒内至少有300个key被改变# save 60 10000 60秒内至少有10000个key被改变save 900 1save 300 10save 60 10000 我这里将值修改如下 1save 10 1 重启redis redis-cli shutdown redis-server redis.conf 12#完成一次set$ set k1 v1 同样的，再data目录下，会发现有一个文件dump6379.rdb 全量复制全量复制的内容会在下一篇文章里描述，这里大致说一下，就是当有主从节点的情况下，从节点会复制主节点的数据，此时主节点会进行一个RDB的生成（与上述说的三种配置无关） debug reload 和 shutdown123# 在redis-cli模式下，以下两条命令都可以使redis发生持久化，生成RDB文件$ debug reload$ shutdown RDB的问题耗时，耗性能耗时，全部数据都要写入一个新的文件，O（N） fork(),，数据量很大的情况下，写的时候会占用很大内存 硬盘的IO性能 不可控，丢失数据这是最最重要的问题，你耗时，我大不了久一点，你好性能，大不了就堆配置 丢数据可不行啊，这是最大的问题 为什么会丢数据呢？？？ save和bgsave都是要手动触发 而配置文件的自动生成rdb文件也是有间隔的，总会存在丢失数据的可能性 AOFAOP就解决了上述一个问题，AOP的原理是这样子的，我每次执行一个set k1 v1的时候就回去AOF文件中去进行一个记录，说白了就是一个日志功能，万一，我执行完set后宕机了，只需要把日志里的动作再做一遍就可以保证数据的恢复 首先AOF是先将命令写入缓冲区，然后再把缓冲区写进AOF文件 AOF的三种策略always：每次都写进everysec：每一秒写进一次no：根据操作系统决定一般来说，折中考虑，会选择everysec，即可保证数据的丢失不会太大，也可以保证IO的开销会没那么大 AOF重写什么是AOF重写，举个例子 123$ set k1 1$ incr k1$ incr k1 AOF会记录三条命令，但是，其实三条命令可以简化成一条命令的，会大大减少我们的AOF的文件，大大加速我们恢复的速度 1$ set k1 3 AOF重写的两种方式 bgrewriteaof，会fork出一个子进程来进行AOF的重写 配置文件 auto-aof-rewrite-min-size：AOF文件需要重写的大小是多少 auto-aof-rewrite-percentage：下一次重写距离这一次重写需要在文件提升多少的百分比的时候进行 aof_current_size：统计当前AOF的大小 aof_base_size：AOF上次启动和重写的尺寸 上demo 首先还是要修改配置文件 12345678910111213#开启append only模式之后，redis会把所接收到的每一次写操作请求都追加到appendonly.aof文件中appendonly yes#AOF的文件名appendfilename &quot;appendonly.aof&quot;#默认使用everysec策略appendfsync everysec#是否会在append的时候，由于请求过长，而阻止no-appendfsync-on-rewrite no#默认的aof的最小文件大小，以及增长率auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb#当aof文件出错的时候，重启的时候是否忽略错误aof-load truncated yes 123# 插入两条数据$ set k1 v1$ set k2 v2 去data目录下会发现有aof的文件生成 把文件删除掉 12# 手动生成AOF文件$ bgrewriteaof 可以看到也是有AOF文件生成的 RDB与AOF的区别 命令 RDB AOF 启动优先级 低 高 体积 小 大 恢复速度 快 慢 数据安全性 丢数据 根据策略决定 轻重 重 轻 RDB的选择 在单机操作大多数情况下，建议关闭 当数据恢复的量级比较大的情况下建议开启 在集群的情况下，建议从节点开 AOF的最佳选择 在单机大多数操作情况下，建议开启 AOF重写集中管理（防止Redis自动做重写操作而导致fork太多引起的内存不足等问题） 建议使用everysec策略]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-工厂方法]]></title>
    <url>%2F2019%2F05%2F14%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[首先在介绍工厂方法之前，先介绍一个新的概念，简单工厂 简单工厂不是一种设计模式 简单工厂 由一个工厂对象来决定创建出哪一种产品类的示例 工厂类负责适合创建的对象比较少的场景 应用层只用传入工厂类的参数，对于如何创建，不关心创建对象的细节 工厂类的职责较重，因为所有对象创建都由工厂类，万一工厂类出了问题，会影响很大 先上Demo,比如我这里是一个玩具厂，生产的玩具有蜘蛛侠和钢铁侠吧,不用简单工厂模式的设计下： 1234567891011121314151617181920212223242526272829303132333435363738/** * 定义一个玩具抽象类 */abstract class AbstractToy &#123; public abstract void produce();&#125;/** * 蜘蛛侠 */class SpiderManToy extends Toy &#123; @Override public void produce() &#123; System.out.println(&quot;我是蜘蛛侠&quot;); &#125;&#125;/** * 钢铁侠 */class IronManToy extends Toy&#123; @Override public void produce() &#123; System.out.println(&quot;我是钢铁侠&quot;); &#125;&#125;/** * 测试类 */public class TestDemo&#123; public static void main(String[] args) &#123; Toy toy = new IronManToy(); toy.produce(); toy = new SpiderManToy(); toy.produce(); &#125;&#125; 这里面存在一个什么问题呢？ 现在我们只有两个玩具而已，如果是三个，四个呢？不断添加一个类来继承我们的抽象类吗？然后不断自己new一个类，这就是高耦合，实现类你要自己编写，业务层你又要自己编写，太麻烦了，看下面示例 12345678910111213141516171819202122** * 玩具工厂类 */class ToyFactory&#123; public static Toy getToy(String name)&#123; if(&quot;IronMan&quot;.equalsIgnoreCase(name))&#123; return new IronManToy(); &#125;else if(&quot;SpiderMan&quot;.equalsIgnoreCase(name))&#123; return new SpiderManToy(); &#125;else&#123; return null; &#125; &#125;&#125;public class TestDemo&#123; public static void main(String[] args) &#123; Toy toy = ToyFactory.getToy(&quot;IronMan&quot;); toy.produce(); toy = ToyFactory.getToy(&quot;spiderman&quot;); toy.produce(); &#125;&#125; 以上代码，将实现类和业务逻辑代码去分开了，业务层只需要去传参数，就可以获取到对应的实现类，如何获取到的细节可以完全不用管理，减少了实业务层和实现层的耦合度，可以分开两个人去对这两个模块进行一个单独的管理，也不会出现问题，业务层只需要传参，工厂那边负责对参数的接收和返回具体的一个实现类以及实现类的编写 以上，业务层已经很好了，但是工厂那一块我们是用了if…else…if这种方法特别不好，写工厂的人，还是和一开始一样，既要自己new具体的实现类，又要编写工厂类，其实本质还是没有发生改变，只是从业务层的麻烦移到工厂上了而已，以上就是我们的简单工厂的做法，所以说，为什么简单工厂只能适合少部分的实例的创建，就是因为一旦管理较多类的情况下，就会导致代码很冗余 工厂方法 定义一个创建对象的接口，让实现这个接口的类来决定实例化哪个类，工厂方法让类的实例化推迟到子类中进行 适用于创建对象需要大量重复代码的时候 应用层不依赖于产品类的实现细节 一个类通过其子类来指定创建哪个对象 重点再说一次：让实现这个接口的类来决定实例化哪个类，工厂方法让类的实例化推迟到子类中进行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 定义一个玩具抽象类 */abstract class Toy &#123; public abstract void produce();&#125;/** * 蜘蛛侠 */class SpiderManToy extends Toy &#123; @Override public void produce() &#123; System.out.println(&quot;我是蜘蛛侠&quot;); &#125;&#125;/** * 钢铁侠 */class IronManToy extends Toy &#123; @Override public void produce() &#123; System.out.println(&quot;我是钢铁侠&quot;); &#125;&#125;/** * 玩具工厂类 */abstract class ToyFactory &#123; public abstract Toy getToy();&#125;/** * 蜘蛛侠工厂 */class SpiderManToyFactory extends ToyFactory&#123; @Override public Toy getToy() &#123; return new SpiderManToy(); &#125;&#125;/** * 钢铁侠工厂 */class IronManToyFactory extends ToyFactory&#123; @Override public Toy getToy() &#123; return new IronManToy(); &#125;&#125;/** * 测试类 */public class TestDemo &#123; public static void main(String[] args) &#123; ToyFactory toyFactory = new SpiderManToyFactory(); Toy toy = toyFactory.getToy(); toy.produce(); &#125;&#125; 这里上一个类图： 一共包含三个大角色，产品，工厂，调用者 其中产品里包含了具体的产品实现 工厂里包含了具体的工厂用来创建具体的产品 使用反射123456789101112131415161718192021222324252627282930/** * 玩具工厂类 */class ToyFactory&#123; public static Toy getToy(Class c) &#123; AbstractToy toy = null; try &#123; toy = (Toy) Class.forName(c.getName()).newInstance(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; return toy; &#125;&#125;/** * 测试类 */public class TestDemo&#123; public static void main(String[] args) &#123; Toy toy = ToyFactory.getToy(IronManToy.class); toy.produce(); toy = ToyFactory.getToy(SpiderManToy.class); toy.produce(); &#125;&#125; 在这里，我使用了反射来解决了在业务层只需要传参数而不用关心其实例创建过程的细节，而每次添加新的类的时候，也不需要修改到工厂类的代码 总结这里讲了三种方法，最后进行一个总结 其中，简单工厂适合实例少的场景，优点是简单，易懂，缺点是违反了开闭原则 工厂方法，有点是，适用实例多的场景，遵循开闭原则，缺点是，比较繁琐 使用简单工厂配合反射，可以解决开闭原则的问题，缺点是使用反射会使程序的效率降低]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-本地镜像发布到阿里云]]></title>
    <url>%2F2019%2F05%2F11%2FDocker-%E6%9C%AC%E5%9C%B0%E9%95%9C%E5%83%8F%E5%8F%91%E5%B8%83%E5%88%B0%E9%98%BF%E9%87%8C%E4%BA%91%2F</url>
    <content type="text"><![CDATA[前面讲到了DockerFile DockerFile是什么来的呢？这里重温一下，DockerFile就是用来构建我们的Docker镜像文件 为什么要学DockerFile?因为拉取的镜像往往功能比较单一，我们有时候会需要根据不同的业务来对我们的虚拟机进行一些定制，这时候就有两种方法可选，一种是DockerFile，一种是执行docker commit,其中DockerFile的灵活性更加高但同时也带有一定的学习难度 本次主要讲解的是本地镜像发布到阿里云 为什么要这么做呢？ 这和我们的代码需要被管理是一个道理，而且，好的东西，开源，不也挺好的吗 本地镜像发布到阿里云的流程 图片看上去很复杂，这里大致解释一下，首先找到一个没有被指向的地方开始看，入口就是DockerFile了，DockerFile build之后成为一个镜像，Docker跑起来就是一个容器，还有两个，一个是阿里云，一个是私有云，说白了就是，你推上去的这个镜像，希不希望让别人能够看到的意思 镜像的生成方法 DockerFile docker commit 将本地镜像推送到阿里云首先进入阿里云控制台创建一个镜像仓库用来存放镜像，代码源我这里选择的是本地仓库 点击管理进入 找到 3. 将镜像推送到Registry 接下来就可以在自己仓库里面可以看到自己push后的镜像 将阿里云的镜像拉取到本地直接docker push 自己的镜像 总结这里涉及到的三条命令 用docker登陆阿里云 用docker push到阿里云 用docker pull从阿里云拉取到本地 这里三条的命令都可以在我的仓库管理里面可以清楚查看，也不用过多的解释]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-原型]]></title>
    <url>%2F2019%2F05%2F05%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8E%9F%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[原型设计模式什么是原型设计模式呢？可以根据我们的名字来推测就是，首先要有个原型，然后根据原型不断来产生新的东西 普通的一个例子看以下代码 1234567891011class Demo&#123; &#125;class Use&#123; public static void main(String[] args) &#123; List&lt;Demo&gt; list = new ArrayList&lt;Demo&gt;(); for (int i = 0; i &lt; 100; i++) &#123; list.add(new Demo()); &#125; &#125;&#125; 这个代码，逻辑上没什么问题，就是new了100个Demo的实例嘛 但是 我这里new了100次啊，100次啊！！！ 太浪费了CPU内存了，结合我们对单例模式的了解，我们可不可以写成单例？肯定可以啊，但是单例获取的只是一个实例，假设我的业务需求真的需要100个呢？难道真的没办法只能new 100次了吗？？ 原型登场12345678910111213141516171819202122class Demo implements Cloneable&#123; private static Demo demo = new Demo(); //禁止实例化 private Demo()&#123;&#125;; //唯一接口获取实例 public static Demo getDemo() throws CloneNotSupportedException&#123; return demo.clone(); &#125; //重写clone方法 @Override protected Demo clone() throws CloneNotSupportedException &#123; return (Demo)super.clone(); &#125;&#125;public class Use&#123; public static void main(String[] args) throws CloneNotSupportedException &#123; List&lt;Demo&gt; list = new ArrayList&lt;Demo&gt;(); for (int i = 0; i &lt; 1000; i++) &#123; list.add(Demo.getDemo()); &#125; &#125;&#125; 这里，原型设计模式核心思想是用到了克隆，克隆这个方法其实就是进行了一个内存块的复制，在创建对象成本较大，如初始化占用较长时间、占用大量cpu资源等，新的对象可以通过原型对象复制产生新的对象。 因为我们的原型设计模式设计到内存块的复制，这里就会产生两个问题 浅复制 深复制 了解对象和引用的区别的朋友都知道，如果单纯拷贝一个内存块，是完全不够的，为什么呢？因为引用！所以上述例子是实现不了引用类型的拷贝 浅拷贝看以下例子 1234567891011121314151617181920212223242526272829303132class A&#123; &#125;class Demo implements Cloneable &#123; private static Demo demo = new Demo(); public A a = new A(); // 禁止实例化 private Demo() &#123; &#125;; // 唯一接口获取实例 public static Demo getDemo() throws CloneNotSupportedException &#123; return demo.clone(); &#125; // 重写clone方法 @Override protected Demo clone() throws CloneNotSupportedException &#123; return (Demo) super.clone(); &#125;&#125;public class Use &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Demo demo1 = Demo.getDemo(); Demo demo2 = Demo.getDemo(); System.out.println(&quot;demo1:&quot; + demo1); System.out.println(&quot;demo2:&quot; + demo2); System.out.println(&quot;demo1:&quot; + demo1.a); System.out.println(&quot;demo2:&quot; + demo2.a); &#125;&#125; 打印结果如下： 1234demo1:demo02.Demo@15db9742demo2:demo02.Demo@6d06d69cdemo1:demo02.A@7852e922demo2:demo02.A@7852e922 出现了一个结果：Object的地址是一样的，说明这里的object是同一个对象，没有实现到拷贝，这就是所谓的浅拷贝，这里上一幅图以供理解 深拷贝12345678910111213141516171819202122232425262728293031323334353637383940class A implements Cloneable&#123; @Override protected A clone() throws CloneNotSupportedException &#123; return (A)super.clone(); &#125;&#125;class Demo implements Cloneable &#123; private static Demo demo = new Demo(); public A a = new A(); // 禁止实例化 private Demo() &#123; &#125;; // 唯一接口获取实例 public static Demo getDemo() throws CloneNotSupportedException &#123; Demo temp = demo.clone(); temp.setA(temp.a.clone()); return temp; &#125; private void setA(A a) &#123; this.a = a; &#125; // 重写clone方法 @Override protected Demo clone() throws CloneNotSupportedException &#123; return (Demo) super.clone(); &#125;&#125;public class Use &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Demo demo1 = Demo.getDemo(); Demo demo2 = Demo.getDemo(); System.out.println(&quot;demo1:&quot; + demo1); System.out.println(&quot;demo2:&quot; + demo2); System.out.println(&quot;demo1:&quot; + demo1.a); System.out.println(&quot;demo2:&quot; + demo2.a); &#125;&#125; 打印结果如下： 1234demo1:demo02.Demo@15db9742demo2:demo02.Demo@6d06d69cdemo1:demo02.A@7852e922demo2:demo02.A@4e25154f 原型设计模式的优缺点优点 如果创建新的对象比较复杂时，可以利用原型模式简化对象的创建过程，同时也能够提高效率 可以使用深克隆保持对象的状态 原型模式提供了简化的创建结构 缺点 在实现深克隆的时候可能需要比较复杂的代码。 需要为每一个类配备一个克隆方法，而且这个克隆方法需要对类的功能进行通盘考虑，这对全新的类来说不是很难，但对已有的类进行改造时，不一定是件容易的事，必须修改其源代码，违背了“开闭原则”。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker---Docker容器数据卷]]></title>
    <url>%2F2019%2F04%2F29%2FDocker-Docker%E5%AE%B9%E5%99%A8%E6%95%B0%E6%8D%AE%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[Docker数据卷使用Docker的时候，我们明白我们跑的都是一个个容器，比如Tomcat，Mysql，Redis等等，既然如此，必须有个东西—–》数据 数据我怎么做一个持久化呢？怎么获取呢？容器奔了我数据就没了吗？ 这时候就有数据卷的诞生 数据卷：一个存放数据的东西，在Docker当中叫做数据卷，可以理解为磁盘，持久存放 数据卷容器：那就是可以理解为存放硬盘的容器，可以理解为移动硬盘 说白点呢，数据是存放在数据卷当中，但是当多个数据卷要进行交互的时候，就需要一个容器来包揽住这些数据卷，这个容器就叫做数据卷容器 数据卷使用-v指令来进行挂载数据卷挂载数据卷就是将本机的某个数据卷（某个文件夹）与容器内共享 docker run -v 宿主机的路径:容器内的路径 镜像名字 12345现在根目录下创建个文件夹$ cd /$ mkdir Doroot执行命令$ docker run -it -v /Doroot:/aaaa --privileged=true centos 注意一下一定要加 –privileged=true 否则容器内部会没有权限 这样子在容器内就能获取到我们宿主机上的数据了，注意一点，此时修改宿主机或者容器内部的数据卷里的文件，都会受到影响，简单来说就是宿主机和容器内布共享数据卷里面的文件 使用DockerFile来添加数据卷以下代码就在容器内挂载了/BBBB，没有指明对应的宿主机位置 123FROM centosVOLUME [&quot;/BBBB&quot;]CMD /bin/bash 然后docker build建立镜像 查看一下容器内挂载的与宿主机对应的位置在哪 123456789101112&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;b3b394fac32e2e263e360de210b36665d03554425d23fe23ad8ebc54aa304716&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/b3b394fac32e2e263e360de210b36665d03554425d23fe23ad8ebc54aa304716/_data&quot;, &quot;Destination&quot;: &quot;/BBBB&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ], /BBBB对应的宿主机位置为 /var/lib/docker/volumes/ b3b394fac32e2e263e360de210b36665d03554425d23fe23ad8ebc54aa304716/_data 因为我们也说过宿主机和容器内布，是共享的，我们可以亲自去测试一下，这里我就不演示了(如果要测试，记得加上特权模式 –privileged =true，否则会报没权限错误) 数据卷容器建立一个容器挂载数据卷，其他容器通过挂载这个容器（父容器）来实现数据共享，挂载数据卷的容器就是数据卷容器 容器之间传递共享 –volumes-from 123456//先创建一个父容器，挂载宿主机$ docker run -it -v /Doroot:/aaaa --name d01 --privileged=true centos//退出容器$ ctrl + P + Q//创建一个子容器$docker run -it --name d02 --volumes-from dc01 --privileged=true centos 此时d02的centos也挂载了容器卷，实现了容器卷的一个传递 此时数据共享，改变任意一个容器的数据卷信息，另外的容器都会受到影响 总结一下数据卷容器，总结之前先抛出几个问题 d01删除后 d02还有吗？ —-有 d01删除后,新建d03继承d02，d03有吗？ —有 d03继承d01后，删除d01,d02和d03可以共享吗？ —可以 结论：容器之间的配置信息的传递，数据卷的生命周期一直持续到没有容器使用为止]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-DockerFile]]></title>
    <url>%2F2019%2F04%2F29%2FDocker-DockerFile%2F</url>
    <content type="text"><![CDATA[Docker深入前面讲解了Docker的基本概念以及Docker的安装，还简单跑了一个例子，相信能够对Docker有一个大致的了解 本章将对Docker进一步的探索 DockerFileDockerFile是用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本。 DockerFile就是用来构建Docker镜像的，现在DockerHub上面有很多镜像，但是有时候我们会根据需求来自定义镜像，（比如说我们要改造Centos）常用两种方法： 我们在DockerHub上面拉取一个镜像下来，然后进入容器里面进行修改，接着进行docker commit（形成新的一个镜像） 我们自己编写DockerFile文件，因为所有镜像本质都是DockerFile，编写完自己构建出一个镜像 DockerFile和 docker commit 的区别： DockerFile更加灵活，我可以随时根据需求来更改我的文件而docker commit，不具备重复性，什么意思呢，就是说，在DockerFile我不要一个东西，只是删除一行就好了（因为这是构建文件，我把某一块去掉就可以了），但是如果用docker commit就不行了，你安装了好些东西，要删除可能得一个个卸载，而且有时候你想要回复到之前某个点的，就非常困难了，所以：构建镜像不推荐docker commit,请使用DockerFile 构建DockerFile三步骤 编写DockerFile文件 docker build docker run 写一个例子吧： 新建一个DockerFile文件编写以下内容 1234From centosENV mypath /tmpWORKDIR $mypathCMD /bin/bash 执行docker build命令 我这里遇到过一个小问题，很多也遇到了，就是build的时候报错 docker build -f 文件所在的位置 -t 名字：版本号 . 如果文件在当前目录下可以省略-f 1$ docker build -f /dockerFile/DockerFile -t mycentos:2.2 . 重要的事情说三遍 最后面有小数点！！！ 最后面有小数点！！！ 最后面有小数点！！！ 1234//不加小数点报错：$ &quot;docker build&quot; requires exactly 1 argument(s).//没启动docker报错：$ Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? 可以看到当前的目录是tmp，因为我构建镜像的时候就设置了WORKDIR 简单的例子讲完了： 现在看看常用的构建文件命令： FROM 基础镜像，当前镜像是基于哪个镜像，可以想象成类与类之间的继承关系 MAINTAINER，镜像的维护者的姓名和邮箱地址 RUN，容器构建时需要运行的命令 EXPOSE，当前容器对外暴露出的端口 WORKDIR，指定创建容器后，终端默认登陆进来的工作目录 ENV，用来构建镜像过程中设置环境变量 ADD，将宿主机的目录下的文件拷贝到镜像里面并且ADD命令会自动处理URL和解压tar COPY，类似ADD，拷贝文件和目录到镜像中。&lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置 VOLUME，容器数据卷，用于保存和持久化工作 CND，指定一个容器启动时要运行的命令，DockerFile中可以有多个CMD指令，但只有最后一个生效，会被docker run 后面的参数给覆盖 ENTRYPOINT，和CMD一样是指定一个容器启动时要运行的命令，区别在于不会被覆盖，都能执行 ONBUILD，当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的onbuild被触发 这个可能就需要多做才能熟悉其命令了 比如说我们拉取的Centos都是比较纯净的 怎么说呢，什么东西都没有装就对了 比如下面 1234# 继承自centos，在centos基础上安装vimFrom centosRUN yum -y install vimCMD /bin/bash 最后写一个命令稍微复杂一点的 123456789101112131415161718192021222324252627#继承原生TomcatFROM centos#设置作者和邮箱MAINTAINER ymbcxb&lt;353560278@qq.com&gt;#把宿主机当前上下文的c.txt拷贝到容器/usr/local中COPY c.txt /usr/local/cincontainer.txt#把java与tomcat添加到容器中ADD apache-tomcat-9.0.17.tar.gz /usr/local/ADD jdk-8u201-linux-x64.tar.gz /usr/local/#安装VIM编辑器RUN yum -y install vim#设置工作访问时候的落脚点ENV MYPATH /usr/localWORKDIR $MYPATH#配置Java与Tomcat的环境变量ENV JAVA_HOME /usr/local/jdk1.8.0_201ENV CLASSPATH JAVA_HOME/lib/dt.jar:JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/apache-tomcat-9.0.17ENV CATALINA_BASE /usr/local/apache-tomcat-9.0.17ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin#容器运行时监听的端口EXPOSE 8080#启动时运行tomcat用ENTRYPOINT 和 CMD都可以#ENTRYPOINT [&quot;/usr/local/apache-tomcat-9.0.17/bin/startup.sh&quot;]#CMD [&quot;/usr/local/apache-tomcat-9.0.17/bin/startup.sh&quot;,&quot;run&quot;]#启动tomcat并且打印日志CMD /usr/local/apache-tomcat-9.0.17/bin/startup.sh &amp;&amp; tail - F /usr/local/apache-tomcat-9.0.17/bin/logs/catalina.out 温馨提示：记得将对应的Jar包和Tomcat的包和c.txt放到当前目录下 运行 1$ docker run -it -p 9080:8080 -d mytomcat:1.0 然后在浏览器输入对应的网址就可以看到Tomcat的页面，LinuxIp:9080 执行以下命令进入 1$ docker exec -it cotainerId /bin/bash 查看到是存在cincontainer.txt 总结： 关于命令的学习，还是需要多琢磨琢磨，比如你可以手写一个Centos（安装了openssh）这样子，下次你需要用虚拟机的时候只用开启多一个容器，就够了就可以进行SSH连接来玩，玩坏了不过删容器而已，比传统的下载一个虚拟机镜像要方便多了，大大大大大地提高学习效率。]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker初探]]></title>
    <url>%2F2019%2F04%2F23%2FDocker%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[Docker初识什么是Docker呢？ Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal)、OpenStack 集群和其他的基础应用平台。 简单点理解呢：Docker是一个管理容器的平台 简单介绍一下容器和虚拟机： 虚拟机：虚拟出一套硬件，在其之上的一个运行一个完整的操作系统 容器：容器之间互相隔离，但共享这同一份硬件系统 我们平时会在电脑上安装各种软件，比如微信，QQ。那么我们Docker呢，在想的是把一个系统看成一个软件，我们安装一个软件（本质是一个系统），比如，你现在的操作系统有很多软件，假设，你要换到一台新的电脑是不是要重新安装软件呢，这就很麻烦了，我们可以直接把你的系统当作一个软件，直接一安装就和你旧的电脑一摸一样了。 Docker的好处： 轻：开启速度快，因为不像Vmware那样子有一套虚拟化硬件，所以快 开发运维一致性：不会再对环境不一样起争议 弹性大：这点解释下，比如我现在一台服务器不够用的情况下，理论上是要新建一台服务器，但是新建的过程是很费时间的，因为有各种配置文件，所以，在Docker里，当不够用的时候，不过是安装多一个容器的事情，容器里面什么都做好了 安全：怎么捣鼓都是在容器里，实在不行，删了重建而已，不会影响导别的容器 附上一张图，以供了解： 那么Docker有几个核心概念： 仓库 镜像 容器 简单描述如下： 容器呢就是我们实际运行的东西 镜像呢就是用生成容器 这里可以这么理解为：用面向对象的思想来说，镜像就是类，容器就是实例对象 仓库呢就是用来放镜像的 首先简单跑一个Docker例子首先开启我们的虚拟机,我这里是Centos7，不同虚拟机可能有一点点差别，总体来说差别不大： 安装docker这里要注意一点： Centos 需要内核版本为3.8以及以上才能运行Docker (命令不包含$符号) 12//查看内核版本$ uname -r 12//安装docker$ sudo yum install docker 启动docker123456//启动 docker$ systemctl start docker//将 docker 服务设为开机启动$ systemctl enable docker//查看 docker版本，验证启动成功$ docker -v 拉取一个Centos镜像拉取之前，先要搜索 1$ docker search centos OFFICIAL ：代表官方 这里拉取的时候，默认是很慢的，因为使用的源地址是国外的，速度非常非常慢 为了提高速度，可以换取阿里或者网易的源 我这里使用的是阿里云 首先得注册一个阿里云账号，进入控制台找到 在这里可以看到加速器的地址，由于每个人的加速器地址，我这里就教下怎么配置 123456//打开配置文件$ vi /etc/docker/daemon.json//配置下面这段&#123; &quot;registry-mirrors&quot;: [&quot;https://xxxxx.mirror.aliyuncs.com&quot;]&#125; 接下来开始正式拉取镜像 1$ docker pull centos 12//查看所有镜像$ docker images 什么！！！只有两百M？对的，就是这么小，为什么，因为没有虚拟出一套物理硬件，单纯在硬件之上的层次，就这么小 默认的就是拉取最新版 如果想拉6的怎么办 指定一下就可以了 1$ docker pull centos:centos6 那么我怎么知道标签是多少呢？？？ 去官网https://hub.docker.com/_/centos查就可以了 最后一步！！！ 创建容器12//docker run 镜像名字:标签,这里 -it代表交互$ docker run -it centos:latest 此时就跑起来了 这就跑起来了一个建立在你虚拟机上的一个centos，而且秒开 你可以在这个界面里输入一些Linux指令也是可以行的，如果要退出 有两种方式 1234//第一种 退出容器，且杀死容器，说白了就容器没了$ exec //第二种，退出容器，且容器后台运行，可以重新进入$ ctrl+p+q 12//检查所有容器的状态$ docker ps -a 最后列举一下Docker镜像和容器常用的基本命令 镜像的操作命令： 删除单个镜像 docker rmi name 删除多个镜像 docker rmi name1 name2 删除全部镜像 docker rmi -f $(docker images -qa) 运行一个镜像 docker run [OPTIONS] imagename OPTIONS说明 –name=”容器新名字”: 为容器指定一个名称 -d: 后台运行容器，并返回容器ID，也即启动守护式容器 -i：以交互模式运行容器，通常与 -t 同时使用 -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用 -P: 随机端口映射 -p: 指定端口映射，有以下四种格式ip:hostPort:containerPort ip::containerPort hostPort:containerPort containerPort 容器的操作命令： 启动镜像 docker run images 查看哪些容器在运行 docker ps 查看所有容器 docker ps -a 停止运行中的容器 docker stop id/name 删除一个容器 docker rm id 删除全部容器 docker rm -f $(docker ps -a -q) 重新进入挂起的容器 docker attach id（直接进入容器启动命令的终端，不会启动新的进程） dicker exec -t 是在容器中打开新的终端，并且可以启动新的进程 从容器内拷贝文件到宿主机上 docker cp 容器id名字:路径 宿主机路径 提交容器副本使之成为新的镜像 docker commit 本章就到此结束了，算入个门吧，复杂的东西，后面再讲]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web登陆其实没那么简单]]></title>
    <url>%2F2019%2F04%2F11%2FWeb%E7%99%BB%E9%99%86%E5%85%B6%E5%AE%9E%E6%B2%A1%E9%82%A3%E4%B9%88%E7%AE%80%E5%8D%95%2F</url>
    <content type="text"><![CDATA[一个简单的HTML例子看看用户信息安全标准的HTML语法中，支持在form表单中使用input标签来创建一个HTTP提交的属性，现代的WEB登录中，常见的是下面这样的表单： 12345&lt;form action = &quot;http://localhost:8080/Application/login&quot; method = &quot;POST&quot;&gt; 用户名：&lt;input id=&quot;username&quot; name=&quot;username&quot; type=&quot;text&quot; /&gt; 密码：&lt;input id=&quot;password&quot; name=&quot;password&quot; type=&quot;password&quot; /&gt; &lt;button type=&quot;submit&quot;&gt;登陆&lt;/button&gt;&lt;/form&gt; form表单会在提交请求时,会获取form中input标签存在name的属性，作为HTTP请求的body中的参数传递给后台，进行登录校验。 例如我的账号是user1，密码是123456，那么我在提交登录的时候会给后台发送的HTTP请求如下（Chrome或者FireFox开发者工具捕获，需开启Preserve log）： 可以发现即便password字段是黑点，但是本机仍以明文的形式截获请求。 HTTP协议传输直接暴露用户密码字段在网络传输过程中，被嗅探到的话会直接危及用户信息安全，以Fiddler或Wireshark为例，发现捕获的HTTP报文中包含敏感信息： 使用加密算法能保证密码安全吗？WEB前端可以通过某种算法，对密码字段进行加密后，在将密码作为Http请求的内容进行提交，常见的包括对称和非对称加密。 对称加密:采用对称密码编码技术，它的特点是文件加密和解密使用相同的密钥加密。 非对称加密:需要两个密钥，公开密钥（publickey）和私有密钥（privatekey）。公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。 3.1 使用对称加密加密解密在前后台协商后，似乎是个不错的办法，比如，前台使用一个字符串位移+字符串反转的简单方法（举个例子，当然不能这么简单）。 那么这样简单的方法似乎可以混淆原密码，并且轻松由后台进行相反操作复原。但是这有两个缺点： 前后端加密解密需要同时修改代码； 前端加密无非是写在JS里，但是JS有风险被直接破解从而识别加密方法。 3.2非对称加密HTTPS就一定是安全的吗？非对称加密有着公钥私钥的存在，公钥可以随意获取，私钥是用来对公钥解密的本地存储，通过公私钥的机制似乎可以保证传输加密并且乃至现在还在使用的HTTPS就是基于这个原理。但是HTTPS就一定安全吗？HTTP存在两种可能的风险： HTTPS可以保证传输过程中的信息不被别人截获，但是细细思考下，HTTPS是应用层协议，下层采用SSL保证信息安全，但是在客户端和服务端，密文同样是可以被截获的； HTTPS报文在传输过程中，如果客户端被恶意引导安装“中间人”的WEB信任证书，那么HTTPS中的“中间人攻击”一样会将明文密码泄露给别人。 结论是，无论HTTP还是HTTPS，密码必须密文传输想想HTTPS也不能一定保障用户密码信息，那么就应该考虑在应用层之上再继续对密码进行保护，也就是编写代码来进行控制，而不依赖特定协议，比较容易想到的就是利用不可逆加密散列函数MD5(string)，用户在注册输入密码的时候，就存储MD5(password)值，并且在WEB端先进行MD5(password)，然后将密码传输至后台，与数据库中的密文进行比较（PS：MD5函数在指定位数的情况下，对相同字符串运算值相同）。优点比较明显： 保证了用户数据库内部的密码信息安全； 传输过程中无论如何都不会使得用户的密文被破解出原密码； 简单高效，执行以及编码难度都不大，各种语言都提供MD5支持，开发快。 那太好了！这样可以省下HTTPS的钱了，真是这样吗？回到开头的例子：用户输入的用户名是：user1，密码是：123456，那么不管在什么协议之下，可以看到实际发送的HTTP/HTTPS报文在MD5处理后是这样的： 没错，加密登录成功了。但是，当我们庆祝密码安全的时候，发现账户的钱突然不翼而飞。这是为什么呢？黑客却笑的很开心：因为他们并不一定要获取到你的密码明文，如果直接截获你的密码密文，然后发送给服务器不是一样可以登录吗？因为数据库里的不也是MD5(password)的一样的密文吗？HTTP请求被伪造，一样可以登录成功，从而攫取其他的数据或者转走余额。 这怎么办?其实并不难，有很多种解决方法？其实原理都是类似的：那就是服务器缓存生成随机的验证字段，并发送给客户端，当客户端登录时，把这个一并字段传给服务器，用于校验。 方案一：验证码MVC场景。控制器将把数据的Model封装到View中，这种存在Session的连接方式，允许了在Session中存取信息。那么我们可以利用一些开源的验证码生成工具，例如JAVA中的Kaptcha，在服务端存放生成一个验证码值以及一个验证码的生成图片，将图片以Base64编码，并返回给View，在View中解码Base64并加载图片，并于用户下次登录时再进行比对。 方案二：token令牌前后端分离场景。现在非常流行的前后端分离的开发模式大大提高了项目的开发效率。职责、分工明确，但是由于HTTP是无状态的（就是这一次请求并不知道上一次请求的内容），当用户登录时，根据用户的username作为key，生成随机令牌（例如UUID）作为value缓存在Redis中，并且将token返回给客户端，当客户端登录时，将完成校验，并且删除Redis中的那条缓存记录。 那么每次从服务器中获取认证的token，确实能保证HTTP请求是由前端传回来的了，因为token在每次登陆后都会删除并被重置，会导致黑客尝试重放账号密码数据信息来登陆的时候导致无法成功登陆。 总而言之，就是我拿到了账号以及密码的密文也登陆不了，因为，如果请求不包含后台认证的令牌token，是个非法请求。 可是还别高兴的太早，当心数据被篡改密码也加密了，黑客看不到明文了。加上Token了，登陆过程也没法再被截获重放了。可是想想这种情况，你在进行某宝上的网络支付，需要账号，密码，金额，token这四个字段进行操作，然后支付的时候你付了1块钱买了一袋包邮的小浣熊干脆面，某宝结算结束后，你发现你的账户余额被扣了1万元。这又是怎么回事呢？ 因为即便黑客不登录，不操作，一样要搞破坏：当请求路由到黑客这边的时候，截获数据包，然后也不需要登录，反正账号密码都是对的，token也是对的，那么把数据包的字段改改，搞破坏就可以了，于是把money改成了1万，再传给服务器，作为受害者就莫名其妙踩了这个坑。可这该怎么解决呢？其实原理类似于HTTPS里的数字签名机制，首先科普下什么是数字摘要以及数字签名： 什么是“数字摘要”我们在下载文件的时候经常会看到有的下载站点也提供下载文件的“数字摘要“，供下载者验证下载后的文件是否完整，或者说是否和服务器上的文件”一模一样“。其实，数字摘要就是采用单项Hash函数将需要加密的明文“摘要”成一串固定长度（128位）的密文，这一串密文又称为数字指纹，它有固定的长度，而且不同的明文摘要成密文，其结果总是不同的，而同样的内容信息其摘要必定一致。 因此，“数字摘要“叫”数字指纹“可能会更贴切一些。“数字摘要“是HTTPS能确保数据完整性和防篡改的根本原因。 数字签名–水到渠成的技术假如发送方想把一份报文发送给接收方，在发送报文前，发送方用一个哈希函数从报文文本中生成报文摘要,然后用自己的私人密钥对这个摘要进行加密，这个加密后的摘要将作为报文的”签名“和报文一起发送给接收方，接收方首先用与发送方一样的哈希函数从接收到的原始报文中计算出报文摘要，接着再用发送方的公用密钥来对报文附加的数字签名进行解密，如果这两个摘要相同、那么接收方就能确认报文是从发送方发送且没有被遗漏和修改过！这就是结合“非对称密钥加解密”和“数字摘要“技术所能做的事情，这也就是人们所说的“数字签名”技术。在这个过程中，对传送数据生成摘要并使用私钥进行加密地过程就是生成”数字签名“的过程，经过加密的数字摘要，就是”数字签名“。 因此，我们可以在WEB端对之前案例中提到的username+MD5(password)+token通过签名，得到一个字段checkCode，并将checkCode发送给服务器，服务器根据用户发送的checkCode以及自身对原始数据签名进行运算比对，从而确认数据是否中途被篡改，以保持数据的完整性。 总结看似非常简单的WEB登录，其实里面也存在着非常多的安全隐患。这些安全完善的过程是在一个实际WEB项目中遇到的，上面的分析演化是在应对项目安全的检查中所提出的解决方案，多少会有很多不足的地方，希望一起交流探讨，共同进步！ 补充1：JS加密函数存在被破解问题： 12如果黑客通过阅读前端js源码,发现加密算法,是否意味他可以构造可以被服务端解密的checkCode 来欺骗服务端呢 ? 回答: 1摘要或加密JS算法不直接以静态文件的形式存在浏览器中，而是让WEB端去请求Server，服务器可以根据随机令牌token值决定返回一个相应随机的加密策略，以JS代码响应的方式返回，在异步请求响应中，加载JS摘要算法，这样客户端就可以动态加载数字摘要策略，保证无法仿造。 补充2：MD5存在隐患的问题问题： 1用MD5、SHA256 处理密码的过时了。。。现在 PBKDF、bcrypt 都在过时中。 回答： 123456789本文重点侧重于方法思路的介绍，并不一定是要使用MD5函数，可以使用其他的方式。MD5存在隐患，之前确实没有考虑太多，不过非常感谢园友指出，确实是这样的，主要思想是：对于MD5的破解，实际上都属于【碰撞】。比如原文A通过MD5可以生成摘要M，我们并不需要把M还原成A，只需要找到原文B，生成同样的摘要M即可。设MD5的哈希函数是MD5()，那么：MD5(A) = MMD5(B) = M任意一个B即为破解结果。B有可能等于A，也可能不等于A。大概意思也就是，截获了MD5加密后的密文，一样可以，找到一个不是原密码，但是加密后可以登陆成功的“伪原文”。 CSDN有一篇关于MD5风险的博客写的非常好，推荐一下：MD5算法如何被破解 从中可以看到一点，MD5函数确实能被反向“破解”，但是这个“破解”只是找到一个经过MD5运算后得到相同结果的原文，并非是用户的明文密码。但是这样会被破解登录的可能，确实是需要采用更完善的算法进行加密，再次感谢！]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Web登陆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一条SQL语句的执行过程]]></title>
    <url>%2F2019%2F04%2F09%2F%E4%B8%80%E6%9D%A1SQL%E8%AF%AD%E5%8F%A5%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Mysql基本架构示意图 大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。 Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL5.5.5 版本开始成为了默认存储引擎。 也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同 连接器连接器是连接我们客户端和服务器首先经过的第一个功能模块，当我们连接我们的Mysql的时候，首先就会执行一条语句 1mysql -h[ip地址] -P[端口号] -u[用户名] -p[密码] 这条语句做的事情就是让本机连接上远端或者本地的Mysql服务器，从而进行管理Mysql 此时连接器就是用来验证我们的用户名和密码是否正确的，正确则可以得到操作的权限，其实就是和我们网站的第一个入口—&gt;登陆是一个意思，进行用户验证 如果连接了之后,没有别的操作，则当前连接就正处于一个空闲状态 当连接上数据库的时候，会保持一个连接，这个连接是长连接，直到连接关闭，否则一直保持连接，中途所有的客户端请求，都由该连接进行工作。短连接只能保证客户端在某个时间段的请求由该连接进行工作，下次查询将会使用一个新的连接 使用长连接也会由问题： 因为长连接保持连接，所以长时间下来，当连接数很多的时候，所占用的内存就会很多 解决办法如下： 1.定期断开长连接 2.Mysql5.7版本之后，每次执行一个比较大的操作后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，速度会比较快 查询缓存我们首先可以查看mysql关于缓存的配置 query_cache_type: 查询缓存类型,是否打开缓存 可选项 1、0(OFF)：关闭 Query Cache 功能，任何情况下都不会使用 Query Cache； 2、1(ON)：开启 Query Cache 功能，但是当SELECT语句中使用SQL_NO_CACHE提示后，将不使用Query Cache； 3、2(DEMAND)：开启Query Cache 功能，但是只有当SELECT语句中使用了SQL_CACHE 提示后，才使用Query Cache。 备注1: 如果query_cache_type为on而又不想利用查询缓存中的数据，可以用下面的SQL： 1SELECT SQL_NO_CACHE * FROM my_table WHERE condition; 如果值为2，要使用缓存的话，需要使用SQL_CACHE开关参数： 1SELECT SQL_CACHE * FROM my_table WHERE condition; 但是大多情况下，建议不要使用查询缓存，因为查询缓存的失效非常频繁，任意一个表的更新操作，这个表上的所有查询缓存都会被清空了，所以查询缓存的命中率非常低，除非表中基本上只会涉及到查操作而很少更新操作的时候可以考虑使用查询缓存的方式 Mysql8.0没有查询缓存的功能，已被彻底抛弃 分析器往上说的，如果开启了缓存机制的，就在缓存里查，否则就要走分析器了，所谓分析器，就是判断你输入的这条语句到底是什么意思，是要做查操作呢还是更新操作呢，还是语法有错误呢，都是由分析器去做的事情 优化器经过了分析器，Mysql就知道你要做的是查还是更新还是什么，此时，到优化器，顾名思义，就是如何优化你查的方式 比如： 1select * from t1 join t2 using(ID) where t1.c = 10 and t2.d =20 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2里面 d 的值是否等于 20。 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1里面 c 的值是否等于 10。 这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。 执行器通过分析器，知道要做什么了，通过优化器知道选择什么的方式做了，执行器就是根据上面的两个结论去做，调用InnoDB引擎去取表中的数据 总结这就是Mysql的逻辑架构，对一个Sql语句完整执行流程的各个阶段有一个初步的认识]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos搭建git私服]]></title>
    <url>%2F2019%2F03%2F26%2FCentos%E6%90%AD%E5%BB%BAgit%E7%A7%81%E6%9C%8D%2F</url>
    <content type="text"><![CDATA[Centos搭建GIT私服安装gitCentos默认自带Git 可以通过以下命令进行查看 1git --version 默认是1.8 创建用户123groupadd gitadduser git -g gitpassword git 先创建一个用户组 再在这个用户组里面创建一个用户 再给用户设置密码 创建authorized_keys文件1234567cd /home/gitmkdir .sshchmod 700 .sshtouch .ssh/authorized_keyschmod 600 .ssh/authorized_keyscd /homechown -R git:git git 要注意的是文件权限和所属用户。 (后续的git clone如果需要密码，很有可能是git用户没有访问authorized_keys文件的权限) 客户端创建密钥并上传1ssh-keygen -t rsa -C &quot;your_email&quot; 该命令会产生两个文件: id_rsa对应私钥，id_rsa.pub对应公钥。 将id_rsa.pub中的内容写到服务器的authorized_keys文件中。 如果有多个客户端，那么在authorized_keys文件中，一行保存一个客户端的公钥。 创建git仓库为了方便管理，所有的git仓库都置于同一目录下，假设为/home/gitrepo， 123cd /homemkdir gitrepochown git:git gitrepo 接下来创建git仓库：test.git 12cd gitrepogit init --bare test.git 把仓库所属用户改为git 1chown -R git:git test.git 注意每次新建的仓库，都要修改仓库的所属用户 git私服搭建完毕push 和 clone示例 打开git bash 1234git clone git@ip:/home/gitrepo/test.gitgit remote add origin git@ip:/home/gitrepo/test.gitgit push -u origin]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git-进阶]]></title>
    <url>%2F2019%2F01%2F31%2FGit-%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[Git进阶本地分支管理一个项目如果是你一个人开发，那就没什么，反正就一份项目，你想做哪个模块就做哪个模块但是这样子开发效率慢啊 要是两个人开发，开发效率提高一倍，那么怎么合并起来呢？？？ 如果说两个人做的地方，刚好互不影响，那很简单，学过数学的人都知道，直接合并起来嘛 问题来了！！！ 如果两个人做的地方有重复怎么办？？？一行一行对比，然后一行行改?还是说一个人做完再让另外一个人做？那这和一个人做有什么区别 这就太麻烦了 所以引入了分支管理！这是个好东西 创建分支根据上图我们可以知道，我们首先是有一个主干的(称为master分支) 我们每次提交，会多一个新的节点 提交越多，master分支也会边长 创建分支的代码：(新的分支名字为dev) 1git branch dev 我们可以看到一个*标记在master，这代表着我们操控着master分支假设我们要切换分支： 1git checkout dev (我们也有一个更加方便的代码，创建分支同时切换到该分支上)： 1git checkout -b dev 接下来，我们执行一次提交 然后我又返回到master里再提交一次 合并分支首先切换到master分支将dev分支合并到master分支下 1git merge dev 删除分支1git branch -d dev GitHub上实现分支管理上面说这么多，其实为了熟悉一下命令，还有通过一些图来表明，每个操作，到底发生了什么 接下来才是实际开发中会用到的，结合GitHub上讲解 首先我拉取一下我Github，我仓库里只有一个A.txt,里面有句Hello 我新建两个文件夹用来模拟两台电脑 接着做如下操作 然后把文件都添加到本地仓库中 接着在Git2里推送到github上的分支下12git checkout -b devgit push -u origin dev 这样子在Github上就有分支了 接着Git去上传自己的到github的master下1git push -u origin master 在创建一个文件夹Git3 分别把两个分支拉下来 1234567git clone 路径进入仓库git checkout dev git clone -b dev(分支名) 路径git checkout mastergit merge devgit push -u origin master]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git入门]]></title>
    <url>%2F2019%2F01%2F13%2FGit%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[版本控制器：首先了解Git之前要明白另外一样东西，那就是版本控制系统 什么叫版本控制系统呢？ 版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理，是软件配置管理的核心思想之一。 程序员写代码，学会一种版本控制器是必不可少的技能 写代码，少不了的就是不断的修改源代码，但是代码是一种很神奇的东西，你会发现，原本只有一个BUG的改着改着突然发现BUG数量不仅仅没有减少而且还增加，此时的心里感受，哈哈，应该要吐血，那么怎么办？我原来的代码也被我改掉了说白了就是已经没有的备份，那就凉了~ 好的，小白曾经是这么干的，比如说，出现BUG吗，那我要修改，修改之前，先拷贝一份现在的源文件，然后再去改，这样子就稳了 当然小白一开始做得还是很开心的，因为很简单啊，写的代码也不多，而且往往只是一个文件，随着小白的进步当中，代码往往牵涉到多个文件的修改，这样子也是可以ctrl+c和ctrl+v的，但是一是一个文件夹里密密麻麻的项目，二是，看着一堆副本一副本二，简直就是头疼啊！！！ 好啦，现在开始讲我们的版本控制器了 简单来说呢，版本控制器就是可以更加方便地对我们的代码进行管理 进入正题： Git:Git：分布式版本控制系统 那么有分布式那么就会有集中式，没错！ SVN就是集中式版本控制系统，本章不做介绍 Git很火的呢，怎么说，GitHub就是基于Git的基础上的 至于分布式版本系统控制系统和集中式版本控制系统，等我把Git和SVN讲解完再进行一个比较 Git的安装Git的安装可以参考官网https://git-scm.com/downloads直接下载后安装后就可以了，很简单 安装后在开始菜单中找到Git Bash鼠标右键也会有 Git的入门我首先创建了一个文件夹，专门进行讲解文件夹名字为Git，首先创建一个文件，名字为a.txt，内容为AAA 接下来进行提交 在文件夹里面右键 git Bash 初始化首先我们要初始化一个仓库，这个仓库是放在我们本机的 1git init 默认为隐藏的，要设置查看隐藏文件就可以看得到多了一个文件夹 添加将文件添加到仓库里 1git add a.txt 提交将文件提交到仓库里 1git commit -m &quot;version 1.0&quot; -m后面是本次提交的一个说明，就是提交的是什么东西(原则上可以省略，但是建议不要) git add 和 git commit的区别首先git add添加自己指定的文件git commit不可以，一次性将所有提交，不可指定文件 git add是先将文件添加到暂存区，git commit将暂存区里的文件一次性提交到仓库里！！！ 基本上简单的一个Git流程的上传部分就介绍完了 下载文件既然前面我们讲完了如何将文件上传到自己的仓库，那么我们现在要用到的情况下，怎么从仓库下载下来呢？？？ 现在为了模仿以下真实环境 我进行多了两次提交 第一次提交之前，在a.txt增加了一行BBB 第二次提交之前，在a.txt增加了一行CCC 接下来我们就要去查看记录了 1git log 当前TXT是这样子的 现在要恢复啦！！！见证奇迹的时刻——- 1git reset --hard HEAD^ 再打开文本，发现已经恢复了，用git log去查看的时候发现也确实少了一条记录HEAD代表的是当前版本HEAD^代表的是当前版本的上一个版本HEAD^^代表的是上上版本 HEAD~N 代表的是当前邦本的上N个版本 远程仓库GitHub是提供Git仓库托管服务的,所以首先要有一个GitHub账号 自行注册GitHub的账号，这个问题，不在这里描述了 其次注册完账号还有做一些事情 先创建一个SSH KEY 1ssh-keygen -t rsa -C &quot;邮箱&quot; 在C盘本地账号下有一个文件夹.ssh 里面有两个文件，分别是id_rsa.pub 和 id_rsa分别对应着公钥和私钥 登陆GitHub，打开Settings里有一个选项，SSH and GPG keys添加自己机子的公钥 因为Git支持SSH协议，所以添加了SSH KEY之后可以防止别人冒充来对我们的仓库进行恶意修改 添加文件到GitHub首先在GitHub里面创建一个Repository 比如说我创建了一个gitTest 然后回到git Bash添加远程仓库1git remote add origin git@github.com:用户名/仓库名字.git 那么对应删除远程仓库的命令：1git remote rm origin 现在我们添加成功之后，接下来就是要上传到远程仓库里面去了 1git push -u origin master 接着去刷新我们的仓库，发现文件已经提交上去了 GitHub上下载文件这个也很简单对应着一条命令就可以了 1git clone git@github.com:用户名/仓库名字.git 好了，本章对Git的介绍就讲到这里，这里只是入门，后面会有一些更加多的内容介绍，敬请关注~]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬取网易云音乐]]></title>
    <url>%2F2019%2F01%2F12%2FPython%E7%88%AC%E5%8F%96%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%2F</url>
    <content type="text"><![CDATA[Python爬取网易云音乐首先放网址： https://music.163.com/ 通过Network我们可以找到我们的音乐url存放的位置 那么我们就简单啦，知道Ajax的请求页面，我们当然就可以直接爬取了，但是： 这个FormData好像不简单，那我怎么请求呢？ 第一直觉，就感觉是被加密了，不愧是网易云，有一套呢 那么肯定就是和JS脱离不了关系了，找到JS，然后保存到本地进行分析一下 把代码保存到本地，进行一些操作 加密用到了四个参数，那么我们可以打印一下这四个参数 那么问题来了，这JS文件在我的本地，我怎么让网站进行加载呢？ 对的，这里要运用到一个工具，Fiddler4 这是个什么东西呢 它能够记录并检查所有你的电脑和互联网之间的Http通讯，设置断点，查看所有的进出Fiddler的数据（cookie,html,css,js） 大概就是，在客户端和服务器之间创建一个代理服务器来对之间进行交互通讯信息进行监控 下载安装完成之后还要对Fiddler4进行配置： Tools—》Options 更详细的介绍，这里就不多说了 那么大概界面是这样的 接着我们打开网易云官网 把core.js拖拉都右边，钩上相应的选项，在最下面找到要替换的JS，最后点击一下save 就能发现上面的路径变了，上图是我已经替换好的了 接下来：在网易云上搜索一首歌，打开控制台 你会发现，居然这样子了： 打印成功了！ 再看XHR里面 我们的重点是url这个，所以我们只用关注第一个打印的，显然ids就是歌曲的序号 多试几组可以看出来一个问题就是： 后三个参数是不用管的 那么歌曲的序号又要怎么获取呢？最终找到的结果是在 然而这个页面也是加密的，很强，没事 我们再看看后台打印的东西 span class = “s-fc7”又是什么东西呢？ 经过测试，发现这是固定的值 整个Json不同的地方在于s，传入歌名就可以了 呼 offset是偏移量，与翻页数有关系 好了，接下来又得去看我们的JS代码，去分析加密过程了 1234567891011121314151617181920212223242526272829303132333435363738function a(a) &#123; var d, e, b = &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&quot;, c = &quot;&quot;; for (d = 0; a &gt; d; d += 1) e = Math.random() * b.length, e = Math.floor(e), c += b.charAt(e); return c &#125; function b(a, b) &#123; var c = CryptoJS.enc.Utf8.parse(b) , d = CryptoJS.enc.Utf8.parse(&quot;0102030405060708&quot;) , e = CryptoJS.enc.Utf8.parse(a) , f = CryptoJS.AES.encrypt(e, c, &#123; iv: d, mode: CryptoJS.mode.CBC &#125;); return f.toString() &#125; function c(a, b, c) &#123; var d, e; return setMaxDigits(131), d = new RSAKeyPair(b,&quot;&quot;,c), e = encryptedString(d, a) &#125; function d(d, e, f, g) &#123; var h = &#123;&#125; , i = a(16); return h.encText = b(d, g), h.encText = b(h.encText, i), h.encSecKey = c(i, e, f), h &#125; function e(a, b, d, e) &#123; var f = &#123;&#125;; return f.encText = c(a + e, b, d), f &#125; window.asrsea = d 首先看函数d 函数d首先有个i，这个i是一个随机的十六位字符串， 然后进行了两次加密，第一次是第一个参数和第四个参数进行加密，把结果返回出来后与i字符串进行第二次加密，这个encText就是我们的params 而通过我们的刚才打印结果来看，后三个参数是固定的，然而i是随机的，也就是我们可以固定一个参数（一个最不可能的坑你，就是每次随机刚好就是随机到我的字符串），也就是说h.encSecKey=c(i,e,f)也是固定的，那也没什么好看的了 最主要的还是我们的params参数的第一次加密，因为第二次加密是在第一次加密的结果和一个固定的字符串，所以也没有讨论的必要了 首先看看我们的加密算法： 12345678910#AES加密算法def AES_encrypt(text, key, iv): pad = 16 - len(text) % 16 if type(text)==type(b&apos;&apos;): text = str(text, encoding=&apos;utf-8&apos;) text = text + pad * chr(pad) encryptor = AES.new(key, AES.MODE_CBC, iv) encrypt_text = encryptor.encrypt(text) encrypt_text = base64.b64encode(encrypt_text) return encrypt_text 这里，要安装一下Crypto模块，不然会报错，模块找不到 接下来就是源代码了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495from Crypto.Cipher import AESimport requestsimport base64import osimport codecsimport jsonfrom pypinyin import lazy_pinyinfrom urllib.request import urlretrieve# 后三个参数和i的值（随机的十六位字符串）b = &apos;010001&apos;c = &apos;00e0b509f6259df8642dbc35662901477df22677ec152b5ff68ace615bb7b725152b3ab17a876aea8a5aa76d2e417629ec4ee341f56135fccf695280104e0312ecbda92557c93870114af6c9d05c4f7f0c3685b7a46bee255932575cce10b424d813cfe4875d3e82047b97ddef52741d546b8e289dc6935b3ece0462db0a22b8e7&apos;d = &apos;0CoJUm6Qyw8W8jud&apos;#随机的十六位字符串def createSecretKey(size): return (&apos;&apos;.join(map(lambda xx: (hex(ord(xx))[2:]), str(os.urandom(size)))))[0:16]#AES加密算法def AES_encrypt(text, key, iv): pad = 16 - len(text) % 16 if type(text)==type(b&apos;&apos;): text = str(text, encoding=&apos;utf-8&apos;) text = text + str(pad * chr(pad)) encryptor = AES.new(key, AES.MODE_CBC, iv) encrypt_text = encryptor.encrypt(text) encrypt_text = base64.b64encode(encrypt_text) return encrypt_text#得到第一个加密参数def Getparams(a,SecretKey): #0102030405060708是偏移量，固定值 iv = &apos;0102030405060708&apos; h_encText = AES_encrypt(a,d,iv) h_encText = AES_encrypt(h_encText,SecretKey,iv) return h_encText#得到第二个加密参数def GetSecKey(text, pubKey, modulus): text = text[::-1] rs = int(codecs.encode(text.encode(&apos;utf-8&apos;), &apos;hex_codec&apos;), 16) ** int(pubKey, 16) % int(modulus, 16) return format(rs, &apos;x&apos;).zfill(256)#得到表单的两个参数def GetFormData(a): SecretKey = createSecretKey(16) params = Getparams(a,SecretKey) enSecKey = GetSecKey(SecretKey,b,c) data = &#123; &quot;params&quot;:str(params,encoding=&apos;utf-8&apos;), &quot;encSecKey&quot;:enSecKey &#125; return datadef getOnePatam(): # 查询id的url url = &apos;https://music.163.com/weapi/cloudsearch/get/web?csrf_token=&apos; #伪装头部 head = &#123; &apos;Host&apos;: &apos;music.163.com&apos;, &apos;Origin&apos;:&apos;https://music.163.com&apos;, &apos;Referer&apos;:&apos;https://music.163.com/search/&apos;, &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&apos;, &#125; print(&quot;输入你想要下载的歌手&quot;) song_name = input() #第一个参数 song_name = &apos;&apos;.join(lazy_pinyin(song_name)) key = &apos;&#123;hlpretag:&quot;&quot;,hlposttag:&quot;&lt;/span&gt;&quot;,s:&quot;&apos;+song_name+&apos;&quot;,type:&quot;1&quot;,csrf_token:&quot;&quot;,limit:&quot;30&quot;,total:&quot;true&quot;,offset:&quot;0&quot;&#125;&apos; FormData = GetFormData(key) html = requests.post(url,headers=head,data=FormData) result = json.loads(html.text) return result[&apos;result&apos;][&apos;songs&apos;]#下载器：def download(name,id): # 获取歌曲的url的路径 song_url = &quot;https://music.163.com/weapi/song/enhance/player/url?csrf_token=&quot; # 伪装头部 headers = &#123; &apos;Host&apos;: &apos;music.163.com&apos;, &apos;Origin&apos;: &apos;https://music.163.com&apos;, &apos;Referer&apos;: &apos;https://music.163.com/&apos;, &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&apos; &#125; # 把上个页面查询到的id放到第二个页面的第一个参数上 a =str(&#123;&apos;ids&apos;: &quot;[&quot;+str(id)+&quot;]&quot;, &apos;br&apos;: 320000, &apos;csrf_token&apos;: &quot;&quot;&#125;) FormData = GetFormData(a) response = requests.post(song_url,data = FormData,headers=headers) json_dict = json.loads(response.content) song_url=json_dict[&apos;data&apos;][0][&apos;url&apos;] print(song_url) folder = os.path.exists(&apos;songs&apos;) if not folder: os.makedirs(&apos;songs&apos;) path = os.path.join(&apos;songs&apos;,name+&quot;.mp3&quot;) urlretrieve(song_url,filename=path)if __name__ == &apos;__main__&apos;: song_list = getOnePatam() for i in song_list: name = i[&apos;name&apos;] id = i[&apos;id&apos;] download(name,id) 以下是效果图 这次程序重点的是对加密的网页，学会如何去处理 有一点要强调一下，因为如果是中文，会导致加密的时候字符串长度不匹配的问题，所以只能用拼音，所以这里加了一个中文转拼音的库，pypinyin的lazy_pinyin()的方法]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solr集群版的搭建]]></title>
    <url>%2F2019%2F01%2F10%2FSolr%E9%9B%86%E7%BE%A4%E7%89%88%E7%9A%84%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Solr集群版的搭建搭建Solr集群 首选需要配置zookeeper集群 先搭建四个tomcat 1234cp -r apache-tomcat-7.0.47 /home/quan/app/solr-cloud/tomcat01cp -r apache-tomcat-7.0.47 /home/quan/app/solr-cloud/tomcat02cp -r apache-tomcat-7.0.47 /home/quan/app/solr-cloud/tomcat03cp -r apache-tomcat-7.0.47 /home/quan/app/solr-cloud/tomcat04 1234vim tomcat01/conf/server.xmlvim tomcat02/conf/server.xmlvim tomcat03/conf/server.xmlvim tomcat04/conf/server.xml 给不同的Tomcat修改端口，tomcat01为81，tomcat02为82,以此类推，主要修改以下三个地方 把单机版的Solr放到Tomcat下 1234cp -r solr /home/app/solr-cloud/tomcat01/webapps/cp -r solr /home/app/solr-cloud/tomcat02/webapps/cp -r solr /home/app/solr-cloud/tomcat03/webapps/cp -r solr /home/app/solr-cloud/tomcat04/webapps/ 再复制四个solrhome到solr-cloud目录下 再修改每个solrhome下的solr.xml 注意写自己的端口号和IP地址 修改每个tomcat的solr的web.xml 修改catalina文件 1234vim tomcat01/bin/catalina.shvim tomcat02/bin/catalina.shvim tomcat03/bin/catalina.shvim tomcat04/bin/catalina.sh tomcat运行catalinda.sh脚本命令 配置JAVA_OPTS 1JAVA_OPTS=&quot;-DzkHost=192.168.25.130:2181,192.168.25.130:2182,192.168.25.130:2183&quot; 在solr文件下的example目录下的script目下的cloud-scripts目录下有个zkcli.sh 上传配置文件至zookeeper的命令 1./zkcli.sh -zkhost 192.168.25.130:2181,192.168.25.130:2182,192.168.25.130:2183 -cmd upconfig -confdir /home/quan/app/solr-cloud/solrhome01/collection1/conf/ -confname myconf 进入solr-cloud的zookeeper01中的bin目录下进行连接zookeeper 1./zkCli.sh -server 192.168.25.130:2182 检查一下 1./zkCli.sh -server 192.168.25.130:2182 myconf就是我们上传的 内容里面有我们上传的solr文件 整个搭建就完成了 开启四个Tomcat 1234/home/quan/app/solr-cloud/tomcat01/bin/startup.sh/home/quan/app/solr-cloud/tomcat02/bin/startup.sh/home/quan/app/solr-cloud/tomcat03/bin/startup.sh/home/quan/app/solr-cloud/tomcat04/bin/startup.sh SolrCloud创建Collection的命令 1http://192.168.25.130:8180/solr/admin/collections?action=CREATE&amp;name=collection2&amp;numShards=2&amp;relicationFactor=2 SolrCloud删除Collection的命令 1http://192.168.25.130:8180/solr/admin/collections?action=DELETE&amp;name=collection1]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Solr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式-单例]]></title>
    <url>%2F2019%2F01%2F07%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[设计模式（Design Pattern）是一套被反复使用、多数人知晓的、经过分类的、代码设计经验的总结。 使用设计模式的目的：为了代码可重用性、让代码更容易被他人理解、保证代码可靠性。 设计模式使代码编写真正工程化；设计模式是软件工程的基石脉络，如同大厦的结构一样。 说白了就是：就是使用设计模式，代码会更好。 单例模式：就是单个实例 那么单例模式有什么好处呢？ 很简单，首先，都是单个实例了，那么就可以怎样 一、实例控制 单例模式会阻止其他对象实例化其自己的单例对象的副本，从而确保所有对象都访问唯一实例。 二、灵活性 因为类控制了实例化过程，所以类可以灵活更改实例化过程。 但是还是有缺点的： 一、开销 虽然数量很少，但如果每次对象请求引用时都要检查是否存在类的实例，将仍然需要一些开销。可以通过使用静态初始化解决此问题。 二、可能的开发混淆 使用单例对象（尤其在类库中定义的对象）时，开发人员必须记住自己不能使用new关键字实例化对象。因为可能无法访问库源代码，因此应用程序开发人员可能会意外发现自己无法直接实例化此类。 三、对象生存期 不能解决删除单个对象的问题。在提供内存管理的语言中（例如基于.NET Framework的语言），只有单例类能够导致实例被取消分配，因为它包含对该实例的私有引用。在某些语言中（如 C++），其他类可以删除对象实例，但这样会导致单例类中出现悬浮引用。。 单例模式根据实例化对象时机的不同分为两种 饿汉式 上代码 12345678910public class Single&#123; /*私有化，防止外部创建实例*/ private Single&#123;&#125; /*设置静态属性私有，防止外部通过类名访问*/ private static Single single = new Single(); /*设置静态方法*/ public static Single getInstance()&#123; return single; &#125;&#125; 这个很简单的 上面有个问题，当类加载的时候，就会实例化Single（），假如我加载完类，一段时间没用，而实例却已经早就创建了，着就会造成一个浪费。 通过这个问题，我们可以想，当我们需要实例的时候我们才去实例化，而不是通过类加载，那么我们可以这样子做 懒汉式 12345678910111213public class Single&#123; /*私有化，防止外部创建实例*/ private Single&#123;&#125; /*设置静态属性私有,先设空，需要的时候再实例化*/ private static Single single=null; /*设置静态方法*/ public static Single getInstance()&#123; if(single==null)&#123; single = new Single() &#125; return single &#125;&#125; 这样子，就没什么问题了 但是现在再思考一个问题，万一是多线程的时候呢？这样就有问题的了 这样子我们就需要加一个锁 12345678910111213141516171819public class Single&#123; /*私有化，防止外部创建实例*/ private Single&#123;&#125; /*设置静态属性私有,先设空，需要的时候再实例化*/ private static Single single=null; /*设置静态方法*/ public static Single getInstance()&#123; /*两重判空是为了提高效率*/ if(single==null)&#123; /*上锁*/ synchronized(Single.Class)&#123; if (single==null) &#123; single = new Single() &#125; &#125; &#125; return single; &#125;&#125; 这样子整个单例模式就做得比较好了]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程]]></title>
    <url>%2F2018%2F12%2F29%2FJava%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[什么是线程？ 线程是一个程序里的不同执行路径 一般的程序是从一个入口出发，沿着唯一的路径走到终点，而线程则使唯一的路径变成多条路径 以下是单线程操作 123456789101112131415161718192021class A extends Thread&#123; public void run() &#123; while(true) &#123; System.out.println(&quot;hello world&quot;); &#125; &#125;&#125;public class Thread1 &#123; public static void main(String[]args) &#123; A aa=new A(); aa.run(); while(true) &#123; System.out.println(&quot;hello JAVA&quot;); &#125; &#125;&#125; 因为aa.run没有执行完毕，下面的while循环就不会执行，所以就是一直输出“hello world“再看看多线程操作 123456789101112131415161718192021class A extends Thread&#123; public void run() &#123; while(true) &#123; System.out.println(&quot;hello world&quot;); &#125; &#125;&#125;public class Thread1 &#123; public static void main(String[]args) &#123; A aa=new A(); aa.start(); while(true) &#123; System.out.println(&quot;hello JAVA&quot;); &#125; &#125;&#125; Thread中的start方法就是创建一个线程，并且自动调用run方法，直接调用run方法是不会创建一个线程的。执行一个线程，其实就是执行一个线程里面的run方法，一个Thread对象不能调用两次start方法，否则会抛出异常。把aa.run改成aa.start结果就是两个循环交替执行，这就是多线程。单线程就是一条路径，从头到尾执行。多线程就是有多条路径，每次都可以走不同的路径。 执行aa.start并不代表aa对象的线程就立刻执行，而是得到了能够被CPU执行的资格，也就是就绪的状态。创建线程的第二种方式： 12345678910111213141516171819202122class A implements Runnable&#123; public void run() &#123; while(true) &#123; System.out.println(&quot;hello world&quot;); &#125; &#125;&#125;public class Thread2 &#123; public static void main(String[]args) &#123; A aa=new A(); Thread th=new Thread(aa); th.start(); while(true) &#123; System.out.println(&quot;hello JAVA&quot;); &#125; &#125;&#125; Thread常用方法： setName（String）设置名字 currentThread（）返回正在执行线程的对象 getName（）返回线程的名字 12345678910111213141516171819class A extends Thread&#123; public void run() &#123; System.out.println(&quot;hello world&quot;); System.out.println(Thread.currentThread().getName()); &#125;&#125;public class Thread1 &#123; public static void main(String[]args) &#123; A aa=new A(); aa.start(); System.out.println(&quot;hello JAVA&quot;); System.out.println(Thread.currentThread().getName()); &#125;&#125; 123456789101112131415161718class A extends Thread&#123; public void run() &#123; System.out.println(&quot;hello world&quot;); System.out.println(Thread.currentThread().getName()); &#125;&#125;public class Thread1 &#123; public static void main(String[]args) &#123; A aa=new A(); aa.setName(&quot;123&quot;); aa.start(); System.out.println(&quot;hello JAVA&quot;); System.out.println(Thread.currentThread().getName()); &#125;&#125; Thread的sleep方法sleep()方法导致了程序暂停执行指定的时间，让出cpu该其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态。要捕获异常！ 123456789101112131415161718192021222324class A extends Thread&#123; public void run() &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(Thread.currentThread().getName()+i); try&#123; Thread.sleep(1000); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Thread1 &#123; public static void main(String[]args) &#123; A aa=new A(); aa.start(); &#125;&#125; Thread的join方法：如a.join（）；暂停当前正在执行的线程，直到a的线程运行终止之后当前线程才有机会得到执行，注意：不是暂停a对象的线程，而是当前运行的线程12345678910111213141516171819202122232425262728class A extends Thread&#123; public void run() &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(Thread.currentThread().getName()+i); &#125; &#125;&#125;public class Thread1 &#123; public static void main(String[]args) &#123; A aa=new A(); aa.start(); try&#123; aa.join(); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; for(int i=0;i&lt;10;i++) &#123; System.out.println(Thread.currentThread().getName()+i); &#125; &#125;&#125; **Thread的优先级： getPriority:获取优先级 setPriority:设置优先级 Java提供一个线程调度器来监控程序中启动后进入就绪状态的所有线程。 线程调度器用数字表现，范围从一到十，一个线程默认是5。 通常优先级高的比优先级低的要先执行，但并不是一定的！因为实际开发中并不单纯依赖优先级来决定优先级的运行顺序** 1234567891011121314151617181920212223242526272829class A implements Runnable&#123; public void run() &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(&quot;A&quot;+i); &#125; &#125;&#125;class B implements Runnable&#123; public void run() &#123; for(int i=0;i&lt;10;i++) &#123; System.out.println(&quot;B&quot;+i); &#125; &#125;&#125;public class Thread3 &#123; public static void main(String[]args) &#123; Thread t1=new Thread(new A()); Thread t2=new Thread(new B()); t1.setPriority(Thread.MIN_PRIORITY); t2.setPriority(Thread.MAX_PRIORITY); t1.start(); t2.start(); &#125;&#125; 优先级越高！越容易被CPU先调用！ 线程的同步卖票系统！ 假如有三个地方，A,B,C同时卖票 假如代码写成这样 12345if(票数大于0)&#123; 买票 票数-1&#125; 当A发现票大于0的时候，本应该执行下一步，假如此时CPU切换的B线程的时候，发现票数大于0（因为在A线程里面，票数没有减一），当在B中发现票数大于0之后，假如CPU又切换到C线程里面，发现票数还是大于0（同理）假如票只有一张，那么此时就相当于一张票被卖了三次。这将产生错误！ 123456789101112131415161718192021222324252627282930class A implements Runnable&#123; private int tickets=100; public void run() &#123; while(true) &#123; if(tickets&gt;0) &#123; System.out.println(Thread.currentThread().getName()+&quot;正在卖出第&quot;+tickets+&quot;张票&quot;); tickets--; &#125; else &#123; break; &#125; &#125; &#125;&#125;public class Thread4 &#123; public static void main(String[]args) &#123; A a=new A(); Thread t1=new Thread(a); t1.start(); A b=new A(); Thread t2=new Thread(b); t2.start(); &#125;&#125; 以上代码运行结果： 每张票都被卖出去两次！！！这是不合理的 导致这个的原因是a对象和b对象都有一个属于自己的tickets 100 那么接下来看以下程序 123456789101112131415161718192021222324252627282930class A implements Runnable&#123; static int tickets=100; public void run() &#123; while(true) &#123; if(tickets&gt;0) &#123; System.out.println(Thread.currentThread().getName()+&quot;正在卖出第&quot;+tickets+&quot;张票&quot;); tickets--; &#125; else &#123; break; &#125; &#125; &#125;&#125;public class Thread4 &#123; public static void main(String[]args) &#123; A a=new A(); Thread t1=new Thread(a); t1.start(); A b=new A(); Thread t2=new Thread(b); t2.start(); &#125;&#125; 把票数改成静态的结果是这样的： 那么来分析一下这个结果是为什么，当Thread-0发现票数是100的时候执行卖出操作，然后立刻切换的线程1然后发现还是100但是没有执行卖出操作又转换为线程0，此时减一然后就变成99、98、97、96、95、这个时候立刻切换成线程1执行卖出操作，打印出来。 简单来说：CPU会在线程之间来回切换！好的，重点来了！Synchronized—同步1234567891011121314151617181920212223242526272829303132class A implements Runnable&#123; static int tickets=100; public void run() &#123; while(true) &#123; synchronized(this) &#123; if(tickets&gt;0) &#123; System.out.println(Thread.currentThread().getName()+&quot;正在卖出第&quot;+tickets+&quot;张票&quot;); tickets--; &#125; else &#123; break; &#125; &#125; &#125; &#125;&#125;public class Thread4 &#123; public static void main(String[]args) &#123; A a=new A(); Thread t1=new Thread(a); Thread t2=new Thread(a); t1.start(); t2.start(); &#125;&#125; 结果如下： synchronized 关键字，代表这个方法加锁,相当于不管哪一个线程（例如线程A），运行到这个方法时,都要检查有没有其它线程B（或者C、 D等）正在用这个方法(或者该类的其他同步方法)，有的话要等正在使用synchronized方法的线程B（或者C 、D）运行完这个方法后再运行此线程A,没有的话,锁定调用者,然后直接运行。它包括两种用法：synchronized 方法和 synchronized 块。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP手动搭建环境]]></title>
    <url>%2F2018%2F12%2F29%2FPHP%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[php环境手动搭建php下载路径https://windows.php.net/download（注意一点的是要下线程安全的Thread Safe） Apache下载路径http://httpd.apache.org/docs/current/platform/windows.html Mysql下载路径https://dev.mysql.com/downloads/mysql/ Apache的安装 这里注意，请先把你的Apache的目录放置好再进行安装，否则安装后再移动位置，会出问题进入Apache目录下的conf目录修改httpd.conf大概在38行附近修改成如下：路径使用自己Apache的安装位置12Define SRVROOT &quot;E:\Apache24&quot; ServerRoot &quot;$&#123;SRVROOT&#125;&quot; 用管理员模式开启CMD进入Apache的bin目录下 命令行httpd -k install进行安装可以使用httpd -t进行测试，是否安装成功 注意事项如果失败，导致原因有可能是： 端口被占用 解决办法： netstat -aon | findstr :80 查看端口是否正在被监听，如果被监听了，有两种方法1. 修改Apache的端口，打开Apache的conf目录下修改httpd.conf,查找Listen关键字 找到 Listen 80 修改到你想设置的端口即可 2. 停止正在监听的服务，打开资源管理器，找到对应的PID，停止运行 这里默认上面三个已经下载好而且已经安装好了 正题：Apache和PHP整合在Apache的conf目录下的httpd.conf文件中加入下面三行代码 12345678#加载PHP模块LoadModule php7_module &quot;E:/php7/php7apache2_4.dll&quot;#当执行后缀为php的文件，就去找这个模块执行AddType Application/x-httpd-php .php#载入php配置文件PHPIniDir &quot;E:/php7&quot; 路径选择你们的位置 在php目录下拷贝php.ini-development改名为php.ini在文件里面进行如下修改(目录为个人的目录)1extension_dir = &quot;E:/php7/ext&quot; 在apache里面有个htdocs目录在里面写入一个php文件比如:test.php123&lt;?php phpinfo(); ?&gt; 在浏览器输入localhost/test.php 如果能够正确显示则配置完成]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solr单机版的搭建]]></title>
    <url>%2F2018%2F12%2F27%2FSolr%E5%8D%95%E6%9C%BA%E7%89%88%E7%9A%84%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Solr Solr是一个开源搜索平台，用于构建搜索应用程序。 它建立在Lucene(全文搜索引擎)之上。 Solr是企业级的，快速的和高度可扩展的。 使用Solr构建的应用程序非常复杂，可提供高性能。 solr的一些突出的特点： Restful APIs − 要与Solr通信，并非一定需要有Java编程技能。相反，您可以使用restful服务与它通信。可使用文件格式(如xml，json和.CSV)在Solr中作为输入文档，并以相同的文件格式获取结果。 全文搜索 - Solr提供了全文搜索所需的所有功能，例如令牌，短语，拼写检查，通配符和自动完成。 企业准备 - 根据企业/组织的需要，Solr可以部署在任何类型的系统(大或小)，如独立，分布式，云等。灵活和可扩展 - 通过扩展Java类并相应配置，可以轻松地定制Solr的组件。 NoSQL数据库 - Solr也可以用作大数据量级的NOSQL数据库，可以沿着集群分布搜索任务。 管理界面 - Solr提供了一个易于使用，用户友好，功能强大的用户界面，使用它可以执行所有可能的任务，如管理日志，添加，删除，更新和搜索文档。 高度可扩展 - 在使用Solr与Hadoop时，我们可以通过添加副本来扩展其容量。 以文本为中心并按相关性排序 - Solr主要用于搜索文本文档，结果根据与用户查询的相关性按顺序传送 Solr单机版的搭建：解压solr和tomcat12tar zxf solr-4.10.3.tgz.tgztar -zxf apache-tomcat-7.0.47.tar.gz 把solr的war包放到tomcat的webapp目录下1cp solr-4.10.3/dist/solr-4.10.3.war /home/quan/taotao/apache-tomcat-7.0.47/webapps/solr.war cp solr-4.10.3/example/lib/ext/* /home/quan/taotao/apache-tomcat-7.0.47/webapps/solr/WEB-INF/lib/123配置一下solrhome vim /home/quan/taotao/apache-tomcat-7.0.47/webapps/solr/WEB-INF/web.xml12修改solr的web.xml vim /home/quan/taotao/apache-tomcat-7.0.47/webapps/solr/WEB-INF/web.xml` 再重新启动一次Tomcat 在浏览器里访问一下 localhost:8080/solr会出现以下界面 整个Solr服务就启动完成了]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>Solr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程和进程]]></title>
    <url>%2F2018%2F12%2F20%2F%E7%BA%BF%E7%A8%8B%E5%92%8C%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[计算机所有可运行的软件，通常也包括操作系统，被组织成若干顺序进程，简称进程。一个进程就是一个正在执行程序的实例 单核CPU也就是单个核心的CPU，每次只能执行一个进程，由于CPU在各进程之间快速切换，所以每个进程所执行的时间是不确定的。 举个例子： 假设你在看着食谱做美食，那么你就相当于CPU，食谱就是程序，而做美食的材料就是输入数据，进程就是，你在阅读食谱取食材以及制作美食的这一系列动作，假设你在做美食时候突然来了个电话，你可能会先熄火，然后脑海里知道自己现在做到哪个位置（保存当前状态），然后去接电话，处理完了后，你可能才回来厨房想想刚才做到哪里了，然后继续之前继续做 一个进程就是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被多个进程共享，CPU使用了某种调度算法决定何时停止一个进程的工作，并且转向另一个进程提供服务。 进程的创建：有四种主要的事件1、系统初始化 前台进程 守护进程2、正在运行的程序执行了创建进程的系统调用3、用户请求创建一个新进程4、一个批处理作业的初始化 进程的终止1、正常退出2、出错退出3、严重错误4、被其他进程给杀死 只可以有一个父进程，但可以有零个或者多个子进程 进程有三种状态：运行态，就绪态，阻塞态 ​ 为了实现进程模型，操作系统维护着一张表格（一个结构数组）即进程表，每个进程占用一个进程表的一个项，这张表包含了许多信息，比如程序计数器，堆栈指针，内存分配状况，等等从而保证了该进程被断掉后重新启动的时候，能够保存之前的信息。 线程为什么需要线程？ 首先，有了线程，我们可以不必考虑终端、定时器、和上下文的切换只需考虑并行进程。其次，线程比进程更加轻量级，速度会比用进程效率要提高很多。 每个单核处理器在某个时刻也是只能够执行一个线程的，这和进程是一样的，线程是CPU处理的基本单位，我们前面讨论的进程，是进程单线程模型。 同样的，线程也是有阻塞态、运行态、就绪态。 为了实现可移植的线程程序，IEEE在IEEE标准中定义了线程的标准，它定义的线程包叫做pthread 实现线程包有两种方法，第一种把整个线程包放在用户空间 从内核的角度上管理的就是单线程进程的模型，这样子尽管系统不支持线程，也可以进行实现 用C语言实现1234567891011121314151617181920212223#include&lt;pthread.h&gt;#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#define NUMBER 10void *hello(void *id)&#123; printf(&quot;Thread-----%d\n&quot;,id); pthread_exit(NULL);&#125;int main()&#123; pthread_t threads[NUMBER]; int status; int i; for(i=0;i&lt;NUMBER;i++)&#123; printf(&quot;Main---Creating thread%d\n&quot;,i); status = pthread_create(&amp;threads[i],NULL,hello,(void*)i); if(status!=0)&#123; printf(&quot;ErrorCode----&gt;%d\n&quot;,status); exit(-1); &#125; &#125; return 0;&#125; 在用户空间管理线程的时候会创建一个运行时的系统，由这个系统进行管理，每个进程都需要其专用的线程表，用来跟踪该进程中的线程。这些表和进程表相似，不过它仅仅记录的是各个线程的属性，如每个线程的程序计数器，堆栈指针，寄存器和状态。因为切换线程的时候不需要陷入到内核空间，不需要有上下文的切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。 用户线程还有一个优点，允许每个进程有自己定制的调度算法，这样子就有一个很好的可扩展性 如果某个线程阻塞了，就会导致整个进程的阻塞 在内核中实现线程 此时不再需要运行时的系统了，另外，每个进程中也没有线程表，内核中有用来记录系统中所有线程的线程表了，当某个线程希望创建一个新的线程的时候，就会进行一个系统的调用，这个系统调用通过对线程表的更新完成线程创建的工作。 内核的线程表里保存了每个线程的信息，这些信息和在用户空间中的线程是一样的，但是现在保存在内核中 由于在内核中创建线程的代价比较大，所以某些系统会采取一种方式：回收线程，当某个线程被撤销的时候，就标记为不可运行的，但是其内核数据的结构没有收到影响。再次创建一个新的线程的时候，就把这个线程给重新启动就可以了，这样子可以减少多次系统调用来开辟新的线程 混合实现 使用内核级的线程，然后将用户级的线程与某些或者全部内核线程多路复用，采取这种方式：开发人员就可以决定有多少个内核级的线程和多少个用户级线程即使多路复用，这个模型可以带来最大的灵活度 进程之间的通信比如说一个购票系统： 进程A和进程B，此时：进程A去买票（一共十张）：首先读出票数，把票数减一，然后把减一后的数据放回去 假设在第二个步骤的时候发生CPU 的切换，进程B去读票数，那么去读的时候此时票数还是10，然后进行减一后，放回去，再切回线程A，放回去，这里就有个问题：同一张票给了两个进程去卖了！这明显是不科学的。 为了有效避免进程的竞争问题这里需要做的就是互斥，那么什么是互斥呢？就是A在访问的时候，禁止B访问，这样子就能够进行一个有效的防止竞争了。 这里面设计很多种方法： 屏蔽中断：每个进程在刚刚进入临界区后立刻屏蔽所有中断，并在就有离开之前再打开终端，屏蔽中断后，时钟中断也会被屏蔽，CPU只有发生时钟中断或者其他中断才会进行切换，这样子，在屏蔽中断之后，CPU将不会进行切换 锁变量：共享一个变量（锁），初始值为0，当一个进程进入临界区的时候，就测试这把锁，如果该锁为0则进程把锁设置为1，然后进入，如果进入的时候锁的值为1，则等待，当出去临界区的时候再把锁的值改为0 严格轮换法： 严格轮换法同样也是针对一个临界区设置一个变量,假设为Turn。以两个进程为例子: 当Turn为0时,Process 0才能能进入临界区,否则等待。等Process 0离开临界区后,将Turn设置为1. 当Turn为1时,Process 1才能进入临界区,否则等待。等Process 1离开临界区后,将Turn设置为0.]]></content>
      <categories>
        <category>技术分享</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
</search>
